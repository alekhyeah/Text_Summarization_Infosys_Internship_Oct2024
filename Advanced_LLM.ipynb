{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Iterative Refinement Implementaion"
      ],
      "metadata": {
        "id": "1xiC5SPgmqH1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU2AJ2AoeRNu",
        "outputId": "0ee91d0d-65d2-4fb1-9693-b7707588f0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -qU langchain_google_genai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "# os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HUGGINGFACEHUB_API_TOKEN')"
      ],
      "metadata": {
        "id": "jery4w_1eXL2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "\n",
        "def load_llm(model=\"gemini-1.5-flash\"):\n",
        "\n",
        "  if model == \"gemini-1.5-pro\":\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-pro\",\n",
        "        temperature=0,\n",
        "        max_tokens=None,\n",
        "        timeout=None,\n",
        "        max_retries=2)\n",
        "    return llm\n",
        "  elif model == \"gemini-1.5-flash\":\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-flash\",\n",
        "        temperature=0,\n",
        "        max_tokens=None,\n",
        "        timeout=None,\n",
        "        max_retries=2)\n",
        "    return llm\n",
        "  else:\n",
        "    raise ValueError(\"Invalid model name\")"
      ],
      "metadata": {
        "id": "lwkbxpz2ebhQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = load_llm()"
      ],
      "metadata": {
        "id": "wyGXJEQbfIwe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(page_content=\"Apples are red\", metadata={\"title\": \"apple_book\"}),\n",
        "    Document(page_content=\"Blueberries are blue\", metadata={\"title\": \"blueberry_book\"}),\n",
        "    Document(page_content=\"Bananas are yelow\", metadata={\"title\": \"banana_book\"}),\n",
        "]"
      ],
      "metadata": {
        "id": "FrmH6LyZfUum"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncCm_qGAfXYj",
        "outputId": "37ff4886-f171-4b5e-e054-f2af0d61a50d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/125.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import List, Literal, TypedDict\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.constants import Send\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "\n",
        "# Initial summary\n",
        "summarize_prompt = ChatPromptTemplate(\n",
        "    [\n",
        "        (\"human\", \"Write a concise summary of the following: {context}\"),\n",
        "    ]\n",
        ")\n",
        "initial_summary_chain = summarize_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Refining the summary with new docs\n",
        "refine_template = \"\"\"\n",
        "Produce a final summary.\n",
        "\n",
        "Existing summary up to this point:\n",
        "{existing_answer}\n",
        "\n",
        "New context:\n",
        "------------\n",
        "{context}\n",
        "------------\n",
        "\n",
        "Given the new context, refine the original summary.\n",
        "\"\"\"\n",
        "refine_prompt = ChatPromptTemplate([(\"human\", refine_template)])\n",
        "\n",
        "refine_summary_chain = refine_prompt | llm | StrOutputParser()\n",
        "\n",
        "\n",
        "# We will define the state of the graph to hold the document\n",
        "# contents and summary. We also include an index to keep track\n",
        "# of our position in the sequence of documents.\n",
        "class State(TypedDict):\n",
        "    contents: List[str]\n",
        "    index: int\n",
        "    summary: str\n",
        "\n",
        "\n",
        "# We define functions for each node, including a node that generates\n",
        "# the initial summary:\n",
        "async def generate_initial_summary(state: State, config: RunnableConfig):\n",
        "    summary = await initial_summary_chain.ainvoke(\n",
        "        state[\"contents\"][0],\n",
        "        config,\n",
        "    )\n",
        "    return {\"summary\": summary, \"index\": 1}\n",
        "\n",
        "\n",
        "# And a node that refines the summary based on the next document\n",
        "async def refine_summary(state: State, config: RunnableConfig):\n",
        "    content = state[\"contents\"][state[\"index\"]]\n",
        "    summary = await refine_summary_chain.ainvoke(\n",
        "        {\"existing_answer\": state[\"summary\"], \"context\": content},\n",
        "        config,\n",
        "    )\n",
        "\n",
        "    return {\"summary\": summary, \"index\": state[\"index\"] + 1}\n",
        "\n",
        "\n",
        "# Here we implement logic to either exit the application or refine\n",
        "# the summary.\n",
        "def should_refine(state: State) -> Literal[\"refine_summary\", END]:\n",
        "    if state[\"index\"] >= len(state[\"contents\"]):\n",
        "        return END\n",
        "    else:\n",
        "        return \"refine_summary\"\n",
        "\n",
        "\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"generate_initial_summary\", generate_initial_summary)\n",
        "graph.add_node(\"refine_summary\", refine_summary)\n",
        "\n",
        "graph.add_edge(START, \"generate_initial_summary\")\n",
        "graph.add_conditional_edges(\"generate_initial_summary\", should_refine)\n",
        "graph.add_conditional_edges(\"refine_summary\", should_refine)\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "KHZWI5uGfZt1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(app.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "Kg1UeZsGfcNt",
        "outputId": "04e9747b-00b6-4741-99e8-57e63f26ed92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async for step in app.astream(\n",
        "    {\"contents\": [doc.page_content for doc in documents]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    if summary := step.get(\"summary\"):\n",
        "        print(summary)\n",
        "\n",
        "\n",
        "\n",
        "async def summarize_documents(user_content: List[str]):\n",
        "    summary = None\n",
        "    async for step in app.astream(\n",
        "        {\"contents\": user_content}, stream_mode=\"values\"\n",
        "    ):\n",
        "        if step.get(\"summary\"):\n",
        "            summary = step[\"summary\"]\n",
        "    return summary\n",
        "\n",
        "user_content = [\n",
        "    \"Artificial Intelligence (AI) is a field of computer science that focuses on creating systems capable of performing tasks that usually require human intelligence.\",\n",
        "    \"Examples of these tasks include learning, reasoning, problem-solving, perception, and language understanding.\",\n",
        "    \"Machine Learning, a subset of AI, involves teaching machines to learn from data and improve over time without being explicitly programmed.\",\n",
        "    \"Deep Learning, a branch of Machine Learning, uses neural networks with many layers to analyze large amounts of data efficiently.\"\n",
        "]\n",
        "summary = await summarize_documents(user_content)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh8MOOytfrQR",
        "outputId": "7df4135a-e532-488e-9240-205913d4a752"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apples can be red.\n",
            "\n",
            "Apples can be red, and blueberries are blue.\n",
            "\n",
            "Apples are red, blueberries are blue, and bananas are yellow.\n",
            "\n",
            "Artificial intelligence (AI) is a branch of computer science focused on creating systems that mimic human intelligence, encompassing learning, reasoning, problem-solving, perception, and language understanding.  A crucial element of AI is machine learning, allowing systems to learn from data and improve without explicit programming.  Deep learning, a subfield of machine learning, leverages multi-layered neural networks to efficiently process and analyze vast datasets, significantly enhancing AI capabilities.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementation of Map Reduce"
      ],
      "metadata": {
        "id": "XiUoHZsTmzT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sVtrb_EgiXfg",
        "outputId": "305e9953-14ab-4f6d-ba22-feadda2fd8b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain_community)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Collecting langchain<0.4.0,>=0.3.8 (from langchain_community)\n",
            "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.8->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.8->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain_community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.19\n",
            "    Uninstalling langchain-core-0.3.19:\n",
            "      Successfully uninstalled langchain-core-0.3.19\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 langchain-0.3.9 langchain-core-0.3.21 langchain_community-0.3.8 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbD3JSK6MiyE",
        "outputId": "451ba478-f200-4de0-9687-40fc4c9b105b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=1000, chunk_overlap=0\n",
        ")\n",
        "\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "docs = loader.load()\n",
        "\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "split_docs = split_docs[0:2]\n",
        "print(f\"Generated {len(split_docs)} documents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sGlU0clftrk",
        "outputId": "355bd90e-3743-41d6-dfc6-34a8f38fdf48"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 1003, which is longer than the specified 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 2 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "map_prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"human\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")]\n",
        ")\n",
        "\n",
        "map_chain = map_prompt | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "PmFEmdlBiT3-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_template = \"\"\"\n",
        "The following is a set of summaries:\n",
        "{docs}\n",
        "Take these and distill it into a final, consolidated summary\n",
        "of the main themes.\n",
        "\"\"\"\n",
        "\n",
        "reduce_prompt = ChatPromptTemplate([(\"human\", reduce_template)])\n",
        "\n",
        "reduce_chain = reduce_prompt | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "AhnGyzKbinCM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langgraph --quiet"
      ],
      "metadata": {
        "id": "lP8H-aUcioxl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, List, Literal, TypedDict\n",
        "\n",
        "from langchain.chains.combine_documents.reduce import (\n",
        "    acollapse_docs,\n",
        "    split_list_of_docs,\n",
        ")\n",
        "from langchain_core.documents import Document\n",
        "from langgraph.constants import Send\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "\n",
        "token_max = 1000\n",
        "\n",
        "\n",
        "def length_function(documents: List[Document]) -> int:\n",
        "    \"\"\"Get number of tokens for input contents.\"\"\"\n",
        "    return sum(llm.get_num_tokens(doc.page_content) for doc in documents)\n",
        "\n",
        "\n",
        "# This will be the overall state of the main graph.\n",
        "# It will contain the input document contents, corresponding\n",
        "# summaries, and a final summary.\n",
        "class OverallState(TypedDict):\n",
        "    # Notice here we use the operator.add\n",
        "    # This is because we want combine all the summaries we generate\n",
        "    # from individual nodes back into one list - this is essentially\n",
        "    # the \"reduce\" part\n",
        "    contents: List[str]\n",
        "    summaries: Annotated[list, operator.add]\n",
        "    collapsed_summaries: List[Document]\n",
        "    final_summary: str\n",
        "\n",
        "\n",
        "# This will be the state of the node that we will \"map\" all\n",
        "# documents to in order to generate summaries\n",
        "class SummaryState(TypedDict):\n",
        "    content: str\n",
        "\n",
        "\n",
        "# Here we generate a summary, given a document\n",
        "async def generate_summary(state: SummaryState):\n",
        "    response = await map_chain.ainvoke(state[\"content\"])\n",
        "    return {\"summaries\": [response]}\n",
        "\n",
        "\n",
        "# Here we define the logic to map out over the documents\n",
        "# We will use this an edge in the graph\n",
        "def map_summaries(state: OverallState):\n",
        "    # We will return a list of `Send` objects\n",
        "    # Each `Send` object consists of the name of a node in the graph\n",
        "    # as well as the state to send to that node\n",
        "    return [\n",
        "        Send(\"generate_summary\", {\"content\": content}) for content in state[\"contents\"]\n",
        "    ]\n",
        "\n",
        "\n",
        "def collect_summaries(state: OverallState):\n",
        "    return {\n",
        "        \"collapsed_summaries\": [Document(summary) for summary in state[\"summaries\"]]\n",
        "    }\n",
        "\n",
        "\n",
        "# Add node to collapse summaries\n",
        "async def collapse_summaries(state: OverallState):\n",
        "    doc_lists = split_list_of_docs(\n",
        "        state[\"collapsed_summaries\"], length_function, token_max\n",
        "    )\n",
        "    results = []\n",
        "    for doc_list in doc_lists:\n",
        "        results.append(await acollapse_docs(doc_list, reduce_chain.ainvoke))\n",
        "\n",
        "    return {\"collapsed_summaries\": results}\n",
        "\n",
        "\n",
        "# This represents a conditional edge in the graph that determines\n",
        "# if we should collapse the summaries or not\n",
        "def should_collapse(\n",
        "    state: OverallState,\n",
        ") -> Literal[\"collapse_summaries\", \"generate_final_summary\"]:\n",
        "    num_tokens = length_function(state[\"collapsed_summaries\"])\n",
        "    if num_tokens > token_max:\n",
        "        return \"collapse_summaries\"\n",
        "    else:\n",
        "        return \"generate_final_summary\"\n",
        "\n",
        "\n",
        "# Here we will generate the final summary\n",
        "async def generate_final_summary(state: OverallState):\n",
        "    response = await reduce_chain.ainvoke(state[\"collapsed_summaries\"])\n",
        "    return {\"final_summary\": response}\n",
        "\n",
        "\n",
        "# Construct the graph\n",
        "# Nodes:\n",
        "graph = StateGraph(OverallState)\n",
        "graph.add_node(\"generate_summary\", generate_summary)  # same as before\n",
        "graph.add_node(\"collect_summaries\", collect_summaries)\n",
        "graph.add_node(\"collapse_summaries\", collapse_summaries)\n",
        "graph.add_node(\"generate_final_summary\", generate_final_summary)\n",
        "\n",
        "# Edges:\n",
        "graph.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n",
        "graph.add_edge(\"generate_summary\", \"collect_summaries\")\n",
        "graph.add_conditional_edges(\"collect_summaries\", should_collapse)\n",
        "graph.add_conditional_edges(\"collapse_summaries\", should_collapse)\n",
        "graph.add_edge(\"generate_final_summary\", END)\n",
        "\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "HO8LvJxkitf5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async for step in app.astream(\n",
        "    {\"contents\": [doc.page_content for doc in split_docs]},\n",
        "    {\"recursion_limit\": 10},\n",
        "):\n",
        "    print(list(step.keys()))"
      ],
      "metadata": {
        "id": "y-vMsEhYi8Nv",
        "outputId": "13661ba4-a1a8-4e1c-ab99-da6cad2805ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['collect_summaries']\n",
            "['generate_final_summary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(step['generate_final_summary']['final_summary'])"
      ],
      "metadata": {
        "id": "Eqz3KFQIi-_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51df497e-be44-4eab-f30b-7cff068c2641"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Both documents discuss Large Language Model (LLM)-powered autonomous agents, focusing on their key architectural components and capabilities.  These components include planning systems (using methods like Chain of Thought, Tree of Thoughts, and external classical planners), memory systems (short-term and long-term, potentially vector databases), and tool-use systems (interacting with external APIs).  The agents' ability for self-reflection, crucial for improved performance and error correction, is highlighted, with examples like ReAct and Reflexion frameworks.  The overall theme emphasizes the evolution of LLMs beyond simple text generation towards general problem-solving agents.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqhS7PlC-MYQ",
        "outputId": "37e4dfc0-e596-4518-b752-195bee7f2f5f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langgraph"
      ],
      "metadata": {
        "id": "P5AkwT2BEFjj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import List, Literal, TypedDict\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.constants import Send\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "\n",
        "# Initial summary\n",
        "summarize_prompt = ChatPromptTemplate(\n",
        "    [\n",
        "        (\"human\", \"Write a concise summary of the following: {context}\"),\n",
        "    ]\n",
        ")\n",
        "initial_summary_chain = summarize_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Refining the summary with new docs\n",
        "refine_template = \"\"\"\n",
        "Produce a final summary.\n",
        "\n",
        "Existing summary up to this point:\n",
        "{existing_answer}\n",
        "\n",
        "New context:\n",
        "------------\n",
        "{context}\n",
        "------------\n",
        "\n",
        "Given the new context, refine the original summary.\n",
        "\"\"\"\n",
        "refine_prompt = ChatPromptTemplate([(\"human\", refine_template)])\n",
        "\n",
        "refine_summary_chain = refine_prompt | llm | StrOutputParser()\n",
        "\n",
        "\n",
        "# We will define the state of the graph to hold the document\n",
        "# contents and summary. We also include an index to keep track\n",
        "# of our position in the sequence of documents.\n",
        "class State(TypedDict):\n",
        "    contents: List[str]\n",
        "    index: int\n",
        "    summary: str\n",
        "\n",
        "\n",
        "# We define functions for each node, including a node that generates\n",
        "# the initial summary:\n",
        "async def generate_initial_summary(state: State, config: RunnableConfig):\n",
        "    summary = await initial_summary_chain.ainvoke(\n",
        "        state[\"contents\"][0],\n",
        "        config,\n",
        "    )\n",
        "    return {\"summary\": summary, \"index\": 1}\n",
        "\n",
        "\n",
        "# And a node that refines the summary based on the next document\n",
        "async def refine_summary(state: State, config: RunnableConfig):\n",
        "    content = state[\"contents\"][state[\"index\"]]\n",
        "    summary = await refine_summary_chain.ainvoke(\n",
        "        {\"existing_answer\": state[\"summary\"], \"context\": content},\n",
        "        config,\n",
        "    )\n",
        "\n",
        "    return {\"summary\": summary, \"index\": state[\"index\"] + 1}\n",
        "\n",
        "\n",
        "# Here we implement logic to either exit the application or refine\n",
        "# the summary.\n",
        "def should_refine(state: State) -> Literal[\"refine_summary\", END]:\n",
        "    if state[\"index\"] >= len(state[\"contents\"]):\n",
        "        return END\n",
        "    else:\n",
        "        return \"refine_summary\"\n",
        "\n",
        "\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"generate_initial_summary\", generate_initial_summary)\n",
        "graph.add_node(\"refine_summary\", refine_summary)\n",
        "\n",
        "graph.add_edge(START, \"generate_initial_summary\")\n",
        "graph.add_conditional_edges(\"generate_initial_summary\", should_refine)\n",
        "graph.add_conditional_edges(\"refine_summary\", should_refine)\n",
        "app = graph.compile()\n",
        "\n",
        "\n",
        "\n",
        "async def summarize_documents(user_content: List[str]):\n",
        "    summary = None\n",
        "    async for step in app.astream(\n",
        "        {\"contents\": user_content}, stream_mode=\"values\"\n",
        "    ):\n",
        "        if step.get(\"summary\"):\n",
        "            summary = step[\"summary\"]\n",
        "    return summary\n",
        "\n",
        "text = '''The Impact of Technology on Modern Education\n",
        "\n",
        "In recent years, technology has revolutionized many aspects of our lives, with one of the most significant changes occurring in the field of education. The introduction of digital tools in classrooms, online learning platforms, and mobile applications has drastically transformed how students learn, how teachers deliver instruction, and how parents support their children's education.\n",
        "\n",
        "One of the most impactful changes has been the introduction of online learning platforms. Platforms like Khan Academy, Coursera, and edX have made it possible for people across the globe to access high-quality education without stepping into a traditional classroom. These platforms offer a range of courses in various fields, often led by experts from top universities, which can be taken at one's own pace. This flexibility has opened up educational opportunities for those who may not have had access otherwise.\n",
        "\n",
        "Moreover, technology has enabled personalized learning experiences. Adaptive learning technologies, such as DreamBox and Smart Sparrow, use artificial intelligence to assess students' understanding of topics and customize the curriculum accordingly. This way, students can work on the areas they struggle with while advancing at their own speed, making learning more efficient and engaging.\n",
        "\n",
        "Despite these benefits, the integration of technology in education also brings challenges. Not all students have access to reliable internet or devices, leading to a digital divide. Students from low-income families may struggle to participate fully in online learning or keep up with assignments if they lack adequate resources. Additionally, there's a growing concern about the amount of screen time students are exposed to, which can impact their physical and mental health.\n",
        "\n",
        "Furthermore, while technology can enhance the learning experience, it cannot replace the value of face-to-face interactions. In-person discussions, group work, and hands-on activities foster social skills and collaboration, which are crucial for holistic development. Teachers and educators must strike a balance between utilizing technology and promoting interpersonal skills in students.\n",
        "\n",
        "In conclusion, technology has brought substantial advancements to education, making it more accessible and customizable. However, it is essential to address the disparities that come with digital learning and to complement technology with traditional educational methods. The future of education lies in a balanced approach, where technology supports and enhances, rather than replaces, the human elements of teaching and learning.\n",
        "'''\n",
        "user_content = sent_tokenize(text)\n",
        "summary = await summarize_documents(user_content)\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "G4Bp4IgtOARh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "collapsed": true,
        "outputId": "f9cb7eef-9e1f-4bc7-e56a-47da4aeb4042"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._achat_with_retry.<locals>._achat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhausted",
          "evalue": "429 Resource has been exhausted (e.g. check quota).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-cbe5c2b70604>\u001b[0m in \u001b[0;36m<cell line: 115>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m '''\n\u001b[1;32m    114\u001b[0m \u001b[0muser_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0msummarize_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-cbe5c2b70604>\u001b[0m in \u001b[0;36msummarize_documents\u001b[0;34m(user_content)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_content\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     async for step in app.astream(\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"contents\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_content\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     ):\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mastream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1865\u001b[0;31m                     async for _ in runner.atick(\n\u001b[0m\u001b[1;32m   1866\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36matick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 await arun_with_retry(\n\u001b[0m\u001b[1;32m    222\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_astream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream, writer)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;31m# if successful, end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mainvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-cbe5c2b70604>\u001b[0m in \u001b[0;36mrefine_summary\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrefine_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRunnableConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"contents\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     summary = await refine_summary_chain.ainvoke(\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"existing_answer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"summary\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"context\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3066\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3068\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3069\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mainvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m     ) -> BaseMessage:\n\u001b[1;32m    306\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         llm_result = await self.agenerate_prompt(\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36magenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    795\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         return await self.agenerate(\n\u001b[0m\u001b[1;32m    797\u001b[0m             \u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36magenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     ]\n\u001b[1;32m    755\u001b[0m                 )\n\u001b[0;32m--> 756\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         flattened_outputs = [\n\u001b[1;32m    758\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item, union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_agenerate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agenerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m                 result = await self._agenerate(\n\u001b[0m\u001b[1;32m    925\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_agenerate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtool_choice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         )\n\u001b[0;32m--> 995\u001b[0;31m         response: GenerateContentResponse = await _achat_with_retry(\n\u001b[0m\u001b[1;32m    996\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_achat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0m_achat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\u001b[0m in \u001b[0;36masync_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0masync_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Preserve attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/_utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mretry_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_error_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_achat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             ) from e\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0m_achat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_achat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_achat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidArgument\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/async_client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         response = await rpc(\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary_async.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             )\n\u001b[0;32m--> 230\u001b[0;31m             return await retry_target(\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mpredicate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary_async.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary_async.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# This function explicitly must deal with broad exceptions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers_async.py\u001b[0m in \u001b[0;36m__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrpc_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpc_error\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrpc_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRed30sC9ZBo"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}