{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMw7XyN+M0vYj3SvaeoXzan",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/springboardmentor0327/Text_Summarization_Infosys_Internship_Oct2024/blob/BandariRohith/Week_7_%26_8_Final_Gradio_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary Libraries"
      ],
      "metadata": {
        "id": "Gu49oCwV02Tk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mxVdHtbisa44"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install gradio --quiet\n",
        "!pip install sumy --quiet\n",
        "!pip install langchain_google_genai --quiet\n",
        "!pip install pypdf --quiet\n",
        "\n",
        "# Import required libraries\n",
        "import gradio as gr\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "import networkx as nx\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from pypdf import PdfReader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK data\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oaKEq5NsfFC",
        "outputId": "8ec9efec-1197-4e95-ce00-a63e385a7e6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up environment variables for API authentication"
      ],
      "metadata": {
        "id": "TNbO1w0S1Aba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('API')"
      ],
      "metadata": {
        "id": "yDkxvrGcvo13"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extractive Methods"
      ],
      "metadata": {
        "id": "hjQyxDx-1Bjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency based"
      ],
      "metadata": {
        "id": "TEZkP7rI1EwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frequency_based_summary(text, max_words):\n",
        "    try:\n",
        "        max_words = int(max_words)\n",
        "        words = word_tokenize(text.lower())\n",
        "        stop_words = set(stopwords.words(\"english\"))\n",
        "        words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "\n",
        "        word_freq = {}\n",
        "        for word in words:\n",
        "            word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "        sentences = sent_tokenize(text)\n",
        "        sentence_scores = {}\n",
        "\n",
        "        for sentence in sentences:\n",
        "            for word in word_tokenize(sentence.lower()):\n",
        "                if word in word_freq:\n",
        "                    sentence_scores[sentence] = sentence_scores.get(sentence, 0) + word_freq[word]\n",
        "\n",
        "        sorted_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)\n",
        "        summary = []\n",
        "        word_count = 0\n",
        "\n",
        "        for sentence in sorted_sentences:\n",
        "            word_count += len(word_tokenize(sentence))\n",
        "            if word_count <= max_words:\n",
        "                summary.append(sentence)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return \" \".join(summary)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "oD0T_Hl2uF0H"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LexRank Based"
      ],
      "metadata": {
        "id": "LF_23wmA1Jus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lexrank_summary(text, max_words):\n",
        "    try:\n",
        "        parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "        summarizer = LexRankSummarizer()\n",
        "        sentences = parser.document.sentences\n",
        "\n",
        "        summary = []\n",
        "        word_count = 0\n",
        "        for sentence in summarizer(parser.document, len(sentences)):\n",
        "            sentence_words = len(word_tokenize(str(sentence)))\n",
        "            if word_count + sentence_words <= int(max_words):\n",
        "                summary.append(str(sentence))\n",
        "                word_count += sentence_words\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return \" \".join(summary)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "AKVIWsiRuJeD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TextRank"
      ],
      "metadata": {
        "id": "QZAlS09y1Mzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def textrank_summary(text, max_words):\n",
        "    try:\n",
        "        max_words = int(max_words)\n",
        "        sentences = sent_tokenize(text)\n",
        "\n",
        "        clean_sentences = []\n",
        "        stop_words = set(stopwords.words(\"english\"))\n",
        "        for sentence in sentences:\n",
        "            words = word_tokenize(sentence.lower())\n",
        "            words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "            clean_sentences.append(\" \".join(words))\n",
        "\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(clean_sentences)\n",
        "        similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "        graph = nx.from_numpy_array(similarity_matrix)\n",
        "        scores = nx.pagerank(graph)\n",
        "        ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(sentences)), reverse=True)\n",
        "\n",
        "        summary = []\n",
        "        word_count = 0\n",
        "        for _, sentence in ranked_sentences:\n",
        "            sentence_words = len(word_tokenize(sentence))\n",
        "            if word_count + sentence_words <= max_words:\n",
        "                summary.append(sentence)\n",
        "                word_count += sentence_words\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return \" \".join(summary)\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "GJOBXGjHuLgg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abstractive methods:"
      ],
      "metadata": {
        "id": "KlcS7STo1PKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T5"
      ],
      "metadata": {
        "id": "MxbtRgZ01ZmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def t5_summary(text, max_words):\n",
        "    try:\n",
        "        max_words = int(max_words)\n",
        "        tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "        model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "        input_text = \"summarize: \" + text\n",
        "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "        summary_ids = model.generate(inputs, max_length=max_words, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "GRDrGINguNWf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bart"
      ],
      "metadata": {
        "id": "bUa_IjX41bEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bart_summary(text, max_words):\n",
        "    try:\n",
        "        max_words = int(max_words)\n",
        "        tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "        model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "        inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "        summary_ids = model.generate(inputs, max_length=max_words, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "TIkFkk9fuQcd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM Methods"
      ],
      "metadata": {
        "id": "OF_Ocf201k4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM-Gemini"
      ],
      "metadata": {
        "id": "MLTiyutA1cSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM (Gemini) summarization\n",
        "def llm_summary(text, max_words):\n",
        "    try:\n",
        "        max_words = int(max_words)\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, max_output_tokens=max_words)\n",
        "        prompt = f\"Summarize the following text in approximately {max_words} words:\\n\\n{text}\"\n",
        "        result = llm(prompt)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "pSpYzaNVuSSL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterative and Map Reduce"
      ],
      "metadata": {
        "id": "CDRbjlt41hyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced LangChain Summarization Techniques\n",
        "def map_reduce_summary(text, max_words):\n",
        "    try:\n",
        "        # Initialize the LLM\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.3, max_output_tokens=max_words)\n",
        "\n",
        "        # Split the text into chunks\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "\n",
        "        # Create documents\n",
        "        docs = [Document(page_content=text)]\n",
        "\n",
        "        # Load map-reduce summarization chain\n",
        "        chain = load_summarize_chain(\n",
        "            llm,\n",
        "            chain_type=\"map_reduce\",\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Run the chain\n",
        "        summary = chain.run(docs)\n",
        "\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Error in Map Reduce Summary: {str(e)}\"\n",
        "\n",
        "def iterative_refinement_summary(text, max_words):\n",
        "    try:\n",
        "        # Initialize the LLM\n",
        "        llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.3, max_output_tokens=max_words)\n",
        "\n",
        "        # Map prompt\n",
        "        map_prompt = PromptTemplate(\n",
        "            template=\"\"\"Write a concise summary of the following text:\n",
        "            \"{text}\"\n",
        "            CONCISE SUMMARY:\"\"\",\n",
        "            input_variables=[\"text\"]\n",
        "        )\n",
        "\n",
        "        # Refine prompt\n",
        "        refine_prompt = PromptTemplate(\n",
        "            template=\"\"\"You are an expert summarizer.\n",
        "            First, review the existing summary and the new piece of text.\n",
        "            Then, refine the summary to include the most important information,\n",
        "            ensuring it captures the key points while staying within the word limit.\n",
        "            Maintain the word limit strictly.\n",
        "            Refined Summary:\"\"\",\n",
        "            input_variables=[\"text\"]\n",
        "        )\n",
        "\n",
        "        # Split the text into chunks\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "        docs = text_splitter.create_documents([text])\n",
        "\n",
        "        # Create the map chain\n",
        "        map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
        "\n",
        "        # Create a chain to combine documents\n",
        "        combine_documents_chain = StuffDocumentsChain(\n",
        "            llm_chain=map_chain,\n",
        "            document_variable_name=\"text\"\n",
        "        )\n",
        "\n",
        "        # Create the summary chain\n",
        "        summary_chain = load_summarize_chain(\n",
        "            llm,\n",
        "            chain_type=\"refine\",\n",
        "            question_prompt=map_prompt,\n",
        "            refine_prompt=refine_prompt,\n",
        "            document_variable_name=\"text\",\n",
        "            return_intermediate_steps=False\n",
        "        )\n",
        "\n",
        "        # Run the chain\n",
        "        summary = summary_chain.run(docs)\n",
        "\n",
        "        return summary\n",
        "    except Exception as e:\n",
        "        return f\"Error in Iterative Refinement Summary: {str(e)}\"\n",
        "\n",
        "def pdf_summarizer(pdf_file, method, max_words):\n",
        "    try:\n",
        "        # Read PDF\n",
        "        reader = PdfReader(pdf_file)\n",
        "\n",
        "        # Extract text from PDF\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "\n",
        "        # Choose summarization method\n",
        "        if method == \"Map Reduce\":\n",
        "            return map_reduce_summary(text, max_words)\n",
        "        elif method == \"Iterative Refinement\":\n",
        "            return iterative_refinement_summary(text, max_words)\n",
        "        elif method == \"T5\":\n",
        "            return t5_summary(text, max_words)\n",
        "        elif method == \"BART\":\n",
        "            return bart_summary(text, max_words)\n",
        "        elif method == \"LLM (Gemini)\":\n",
        "            return llm_summary(text, max_words)\n",
        "        else:\n",
        "            return \"Invalid summarization method selected.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error in PDF Summarization: {str(e)}\"\n",
        "# Extractive Summarization\n",
        "def extractive_summarize(text, algorithm, max_words):\n",
        "    if algorithm == \"Frequency-based\":\n",
        "        return frequency_based_summary(text, max_words)\n",
        "    elif algorithm == \"LexRank\":\n",
        "        return lexrank_summary(text, max_words)\n",
        "    elif algorithm == \"TextRank\":\n",
        "        return textrank_summary(text, max_words)\n",
        "    else:\n",
        "        return \"Invalid extractive summarization algorithm.\"\n",
        "\n",
        "# Abstractive Summarization\n",
        "def abstractive_summarize(text, algorithm, max_words):\n",
        "    if algorithm == \"T5\":\n",
        "        return t5_summary(text, max_words)\n",
        "    elif algorithm == \"BART\":\n",
        "        return bart_summary(text, max_words)\n",
        "    else:\n",
        "        return \"Invalid abstractive summarization algorithm.\"\n",
        "\n",
        "# LLM-based Summarization\n",
        "def llm_summarize(text, algorithm, max_words):\n",
        "    if algorithm == \"LLM (Gemini)\":\n",
        "        return llm_summary(text, max_words)\n",
        "    elif algorithm == \"Iterative Refinement\":\n",
        "        return iterative_refinement_summary(text, max_words)\n",
        "    elif algorithm == \"Map Reduce\":\n",
        "        return iterative_refinement_summary(text, max_words)\n",
        "    else:\n",
        "        return \"Invalid LLM summarization algorithm.\"\n",
        "\n",
        "# PDF Summarization\n",
        "def pdf_summarizer(pdf_file, summarization_type, algorithm, max_words):\n",
        "    try:\n",
        "        pdf_reader = PdfReader(pdf_file)\n",
        "        text = \"\".join(page.extract_text() for page in pdf_reader.pages)\n",
        "\n",
        "        if summarization_type == \"Extractive\":\n",
        "            return extractive_summarize(text, algorithm, max_words)\n",
        "        elif summarization_type == \"Abstractive\":\n",
        "            return abstractive_summarize(text, algorithm, max_words)\n",
        "        elif summarization_type == \"LLM\":\n",
        "            return llm_summarize(text, algorithm, max_words)\n",
        "        else:\n",
        "            return \"Invalid summarization type.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error in PDF summarization: {str(e)}\""
      ],
      "metadata": {
        "id": "0QNHPE5puUud"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradio Interface"
      ],
      "metadata": {
        "id": "9MSRtxpfwOIo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align: center;'>Text Summarization App</h1>\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "\n",
        "            gr.Markdown(\"Select input type and summarization method\")\n",
        "\n",
        "            with gr.Row():\n",
        "                input_type = gr.Radio(\n",
        "                    [\"Text Input\", \"PDF Upload\"],\n",
        "                    label=\"Input Type\",\n",
        "                    value=\"Text Input\"\n",
        "                )\n",
        "\n",
        "                text_input = gr.Textbox(\n",
        "                    label=\"Input Text\",\n",
        "                    lines=5,\n",
        "                    placeholder=\"Enter text here\",\n",
        "                    visible=True\n",
        "                )\n",
        "\n",
        "                pdf_input = gr.File(\n",
        "                    label=\"Upload PDF\",\n",
        "                    type=\"filepath\",\n",
        "                    file_types=[\".pdf\"],\n",
        "                    visible=False\n",
        "                )\n",
        "\n",
        "                summarization_type = gr.Radio(\n",
        "                    [\"Extractive\", \"Abstractive\", \"LLM\"],\n",
        "                    label=\"Summarization Type\",\n",
        "                    value=\"Extractive\"\n",
        "                )\n",
        "\n",
        "                method_dropdown = gr.Dropdown(\n",
        "                    label=\"Algorithm\",\n",
        "                    visible=True\n",
        "                )\n",
        "\n",
        "                words = gr.Textbox(\n",
        "                    label=\"Max Words\",\n",
        "                    value=\"100\"\n",
        "                )\n",
        "\n",
        "            output = gr.Textbox(\n",
        "                label=\"Summary\",\n",
        "                lines=5\n",
        "            )\n",
        "\n",
        "            button = gr.Button(\"Generate Summary\")\n",
        "\n",
        "            def toggle_inputs(choice):\n",
        "                if choice == \"Text Input\":\n",
        "                    return {\n",
        "                        text_input: gr.update(visible=True),\n",
        "                        pdf_input: gr.update(visible=False)\n",
        "                    }\n",
        "                else:\n",
        "                    return {\n",
        "                        text_input: gr.update(visible=False),\n",
        "                        pdf_input: gr.update(visible=True)\n",
        "                    }\n",
        "\n",
        "            input_type.change(\n",
        "                toggle_inputs,\n",
        "                inputs=input_type,\n",
        "                outputs=[text_input, pdf_input]\n",
        "            )\n",
        "\n",
        "            def update_algorithms(summarization_type):\n",
        "                if summarization_type == \"Extractive\":\n",
        "                    return gr.update(choices=[\"Frequency-based\", \"LexRank\", \"TextRank\"], visible=True)\n",
        "                elif summarization_type == \"Abstractive\":\n",
        "                    return gr.update(choices=[\"T5\", \"BART\"], visible=True)\n",
        "                elif summarization_type == \"LLM\":\n",
        "                    return gr.update(choices=[\"LLM (Gemini)\", \"Map Reduce\", \"Iterative Refinement\"], visible=True)\n",
        "                else:\n",
        "                    return gr.update(visible=False)\n",
        "\n",
        "            summarization_type.change(\n",
        "                update_algorithms,\n",
        "                inputs=summarization_type,\n",
        "                outputs=method_dropdown\n",
        "            )\n",
        "\n",
        "            def summarize(input_type, text, pdf, summarization_type, method, max_words):\n",
        "                if input_type == \"Text Input\":\n",
        "                    if summarization_type == \"Extractive\":\n",
        "                        return extractive_summarize(text, method, max_words)\n",
        "                    elif summarization_type == \"Abstractive\":\n",
        "                        return abstractive_summarize(text, method, max_words)\n",
        "                    elif summarization_type == \"LLM\":\n",
        "                        return llm_summarize(text, method, max_words)\n",
        "                    else:\n",
        "                        return \"Invalid summarization type.\"\n",
        "                else:  # PDF Upload\n",
        "                    return pdf_summarizer(pdf, summarization_type, method, max_words)\n",
        "\n",
        "            button.click(\n",
        "                summarize,\n",
        "                inputs=[input_type, text_input, pdf_input, summarization_type, method_dropdown, words],\n",
        "                outputs=output\n",
        "            )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "yXcwHqfXwmJO",
        "outputId": "a076d2dd-9e00-4617-b705-553f33b06e69"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://61a7f6ff2a51279bbb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://61a7f6ff2a51279bbb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JBqsUpYvw5Ik"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}