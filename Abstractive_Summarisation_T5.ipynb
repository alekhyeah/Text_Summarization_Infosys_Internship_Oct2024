{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "akiHNkpteWgt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-vREUdReSs1"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "import glob\n",
        "import pprint\n",
        "\n",
        "pp = pprint.PrettyPrinter()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting Google Drive"
      ],
      "metadata": {
        "id": "MOtpRocOfXTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive in Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "w-5lcHADfby4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf182ac-22a1-4496-abc5-2082cccc4c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting a Directory for Cache in Google Drive\n",
        "\n",
        "import os\n",
        "\n",
        "cache_dir = '/content/drive/MyDrive/transformers_cache'\n",
        "os.makedirs(cache_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "Fv9EaG3sgOZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading T5 Model and Tokenizer and chaching them in Google Drive"
      ],
      "metadata": {
        "id": "VNwGGGyogt45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base', cache_dir=cache_dir)\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base', cache_dir=cache_dir)"
      ],
      "metadata": {
        "id": "bvYlA-hXg13b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a summarize_text function"
      ],
      "metadata": {
        "id": "ZesCK-KvhdCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text, model, tokenizer, min_length=50, max_length=150, num_beams=5):\n",
        "    # Preprocess the text\n",
        "    inputs = tokenizer.encode(\n",
        "        \"summarize: \" + text,\n",
        "        return_tensors='pt',\n",
        "        max_length=512,  # Keep this high to handle long inputs\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    # Generate the summary\n",
        "    summary_ids = model.generate(\n",
        "        inputs,\n",
        "        min_length=min_length,            # Minimum length to avoid too short a summary\n",
        "        max_length=max_length,            # Adjust this to control summary length\n",
        "        num_beams=num_beams,\n",
        "        length_penalty=2.0,               # Higher values encourage longer summaries\n",
        "        no_repeat_ngram_size=3,           # Prevent repetitive phrases\n",
        "        early_stopping=True               # Stops generating when the model thinks it's done\n",
        "    )\n",
        "\n",
        "    # Decode the summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Calculate the word count of the summary\n",
        "    word_count = len(summary.split())\n",
        "\n",
        "    return summary, word_count"
      ],
      "metadata": {
        "id": "joe7SCjIhlII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the function and generating a summary"
      ],
      "metadata": {
        "id": "wVaXsujojCz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "The global smartphone market experienced a significant shift in 2023,\n",
        "with total shipments reaching 1.21 billion units, a decline of 7.1% compared to the previous year.\n",
        "This was primarily due to supply chain disruptions, inflationary pressures, and geopolitical tensions.\n",
        "In contrast, Apple's market share grew from 23.4% in 2022 to 26.5% in 2023, driven by strong demand for the iPhone 14 series,\n",
        "particularly in North America and Europe. Meanwhile, Samsung's market share slightly decreased from 19.1% to 18.7%,\n",
        "despite launching the Galaxy S23 and Galaxy Z Fold 5. Xiaomi retained its third position globally,\n",
        "with an 11.8% market share, but also saw a 10% drop in shipments, largely due to a sluggish market in India.\n",
        "Additionally, 5G-enabled devices accounted for 70% of total smartphone shipments, up from 57% in 2022,\n",
        "reflecting increased consumer demand for faster mobile internet speeds. Analysts predict a rebound in 2024,\n",
        "with smartphone shipments expected to grow by 4.3%, as supply chain constraints ease and\n",
        "new innovations such as foldable screens and AI-powered features become more mainstream.\n",
        "\"\"\"\n",
        "\n",
        "# Call the function and generate the summary\n",
        "summary = summarize_text(text, model, tokenizer)\n",
        "\n",
        "# Print the summary\n",
        "print(\"Summary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ltHDjXnjIw0",
        "outputId": "3db07b14-0255-4fd6-bb3b-6bb787d1eee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "('the global smartphone market experienced a significant shift in 2023. total shipments reached 1.21 billion units, a decline of 7.1% compared to the previous year. analysts predict a rebound in 2024, with smartphone shipments expected to grow by 4.3%.', 39)\n"
          ]
        }
      ]
    }
  ]
}