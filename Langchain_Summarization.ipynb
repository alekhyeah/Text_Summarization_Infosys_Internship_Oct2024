{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONVfCYUbA4A42fyNL8MXgO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tiktoken openai langchain --quiet\n","!pip install langchain.community --quiet\n","\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n","from langchain.chains.mapreduce import MapReduceChain\n","from langchain.chains import ReduceDocumentsChain\n","from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n","from langchain.prompts import PromptTemplate\n","from langchain.chains.summarize import load_summarize_chain\n","import textwrap\n","\n","from google.colab import userdata\n","\n","import os\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get('AAPI')\n","\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0,max_tokens=None,timeout=None,max_retries=2)\n","\n","from langchain_core.documents import Document\n","\n","documents = [\n","    Document(page_content=\"Apples are red\", metadata={\"title\": \"apple_book\"}),\n","    Document(page_content=\"Blueberries are blue\", metadata={\"title\": \"blueberry_book\"}),\n","    Document(page_content=\"Bananas are yelow\", metadata={\"title\": \"banana_book\"}),\n","]\n","\n","def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n","    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n","    docs = text_splitter.split_documents(documents)\n","    return docs\n","\n","docs = split_docs(documents)\n","\n","chain = load_summarize_chain(llm,\n","                             chain_type=\"map_reduce\",\n","                             verbose = False)\n","output_summary = chain.run(docs)\n","wrapped_text = textwrap.fill(output_summary, width=100)\n","print(wrapped_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62YejWZU-V3w","executionInfo":{"status":"ok","timestamp":1731419443704,"user_tz":-330,"elapsed":19824,"user":{"displayName":"Akhil Kunisetty","userId":"10824639933241965364"}},"outputId":"aec31d77-dae5-4af8-97fb-18d2ef41b19c"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Fruits come in various colors, such as red (apples), blue (blueberries), and yellow (bananas).\n"]}]},{"cell_type":"code","source":["#SINGLE CELL LANGCHAIN\n","\n","\n","!pip install -qU langchain-google-vertexai --quiet\n","!pip install --upgrade --quiet langchain langchain-google-genai beautifulsoup4\n","\n","from google.colab import userdata\n","\n","import getpass\n","import os\n","\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"AAPI\")\n","\n","from langchain_google_vertexai import ChatVertexAI\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0,max_tokens=None,timeout=None,max_retries=2)\n","\n","from langchain_core.documents import Document\n","\n","documents = [\n","    Document(page_content=\"Apples are red\", metadata={\"title\": \"apple_book\"}),\n","    Document(page_content=\"Blueberries are blue\", metadata={\"title\": \"blueberry_book\"}),\n","    Document(page_content=\"Bananas are yelow\", metadata={\"title\": \"banana_book\"}),\n","]\n","\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","prompt = ChatPromptTemplate.from_template(\"Summarize this content: {context}\")\n","chain = create_stuff_documents_chain(llm, prompt)\n","\n","result = chain.invoke({\"context\": documents})\n","print(result)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fczKk83DLnri","executionInfo":{"status":"ok","timestamp":1731419535922,"user_tz":-330,"elapsed":11960,"user":{"displayName":"Akhil Kunisetty","userId":"10824639933241965364"}},"outputId":"304d19a4-1f36-426c-d6e8-8917e3a08c52"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["This content describes the colors of three common fruits: apples are red, blueberries are blue, and bananas are yellow. \n","\n"]}]},{"cell_type":"code","source":["#ITERATIVE REFINEMENT\n","\n","\n","!pip install -qU langchain-google-vertexai --quiet\n","!pip install --upgrade --quiet langchain langchain-google-genai beautifulsoup4\n","!pip install -qU langgraph\n","\n","import operator\n","from typing import List, Literal, TypedDict\n","from google.colab import userdata\n","\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.runnables import RunnableConfig\n","from langgraph.constants import Send\n","from langgraph.graph import END, START, StateGraph\n","\n","import getpass\n","import os\n","\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"AAPI\")\n","\n","from langchain_google_vertexai import ChatVertexAI\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0,max_tokens=None,timeout=None,max_retries=2)\n","\n","from langchain_core.documents import Document\n","\n","documents = [\n","    Document(page_content=\"Apples are red\", metadata={\"title\": \"apple_book\"}),\n","    Document(page_content=\"Blueberries are blue\", metadata={\"title\": \"blueberry_book\"}),\n","    Document(page_content=\"Bananas are yelow\", metadata={\"title\": \"banana_book\"}),\n","]\n","\n","######\n","\n","# Initial summary\n","summarize_prompt = ChatPromptTemplate(\n","    [\n","        (\"human\", \"Write a concise summary of the following: {context}\"),\n","    ]\n",")\n","initial_summary_chain = summarize_prompt | llm | StrOutputParser()\n","\n","# Refining the summary with new docs\n","refine_template = \"\"\"\n","Produce a final summary.\n","\n","Existing summary up to this point:\n","{existing_answer}\n","\n","New context:\n","------------\n","{context}\n","------------\n","\n","Given the new context, refine the original summary.\n","\"\"\"\n","refine_prompt = ChatPromptTemplate([(\"human\", refine_template)])\n","\n","refine_summary_chain = refine_prompt | llm | StrOutputParser()\n","\n","\n","# We will define the state of the graph to hold the document\n","# contents and summary. We also include an index to keep track\n","# of our position in the sequence of documents.\n","class State(TypedDict):\n","    contents: List[str]\n","    index: int\n","    summary: str\n","\n","\n","# We define functions for each node, including a node that generates\n","# the initial summary:\n","async def generate_initial_summary(state: State, config: RunnableConfig):\n","    summary = await initial_summary_chain.ainvoke(\n","        state[\"contents\"][0],\n","        config,\n","    )\n","    return {\"summary\": summary, \"index\": 1}\n","\n","\n","# And a node that refines the summary based on the next document\n","async def refine_summary(state: State, config: RunnableConfig):\n","    content = state[\"contents\"][state[\"index\"]]\n","    summary = await refine_summary_chain.ainvoke(\n","        {\"existing_answer\": state[\"summary\"], \"context\": content},\n","        config,\n","    )\n","\n","    return {\"summary\": summary, \"index\": state[\"index\"] + 1}\n","\n","\n","# Here we implement logic to either exit the application or refine\n","# the summary.\n","def should_refine(state: State) -> Literal[\"refine_summary\", END]:\n","    if state[\"index\"] >= len(state[\"contents\"]):\n","        return END\n","    else:\n","        return \"refine_summary\"\n","\n","\n","graph = StateGraph(State)\n","graph.add_node(\"generate_initial_summary\", generate_initial_summary)\n","graph.add_node(\"refine_summary\", refine_summary)\n","\n","graph.add_edge(START, \"generate_initial_summary\")\n","graph.add_conditional_edges(\"generate_initial_summary\", should_refine)\n","graph.add_conditional_edges(\"refine_summary\", should_refine)\n","app = graph.compile()\n","\n","from IPython.display import Image\n","\n","Image(app.get_graph().draw_mermaid_png())\n","\n","async for step in app.astream(\n","    {\"contents\": [doc.page_content for doc in documents]},\n","    stream_mode=\"values\",\n","):\n","    if summary := step.get(\"summary\"):\n","        print(summary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HCRJi0aKN9X4","executionInfo":{"status":"ok","timestamp":1731419578521,"user_tz":-330,"elapsed":20000,"user":{"displayName":"Akhil Kunisetty","userId":"10824639933241965364"}},"outputId":"11e9706f-6b1b-4300-a095-caa7f17a2801"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Apples are typically red in color. \n","\n","Apples are typically red in color, while blueberries are blue. \n","\n","Apples are typically red in color, blueberries are blue, and bananas are yellow. \n","\n"]}]},{"cell_type":"code","source":["#MAP REDUCE\n","\n","\n","!pip install -qU langchain-google-vertexai --quiet\n","!pip install --upgrade --quiet langchain langchain-google-genai beautifulsoup4\n","!pip install -qU langgraph\n","\n","import operator\n","from typing import List, Literal, TypedDict\n","from google.colab import userdata\n","\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.runnables import RunnableConfig\n","from langgraph.constants import Send\n","from langgraph.graph import END, START, StateGraph\n","\n","import getpass\n","import os\n","\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"AAPI\")\n","\n","from langchain_google_vertexai import ChatVertexAI\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0,max_tokens=None,timeout=None,max_retries=2)\n","\n","from langchain_core.documents import Document\n","\n","documents = [\n","    Document(page_content=\"Apples are red\", metadata={\"title\": \"apple_book\"}),\n","    Document(page_content=\"Blueberries are blue\", metadata={\"title\": \"blueberry_book\"}),\n","    Document(page_content=\"Bananas are yelow\", metadata={\"title\": \"banana_book\"}),\n","]\n","\n","############\n","\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","map_prompt = ChatPromptTemplate.from_messages(\n","    [(\"human\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")]\n",")\n","\n","map_chain = map_prompt | llm | StrOutputParser()\n","\n","reduce_template = \"\"\"\n","The following is a set of summaries:\n","{docs}\n","Take these and distill it into a final, consolidated summary\n","of the main themes.\n","\"\"\"\n","\n","reduce_prompt = ChatPromptTemplate([(\"human\", reduce_template)])\n","\n","reduce_chain = reduce_prompt | llm | StrOutputParser()\n","\n","import operator\n","from typing import Annotated, List, Literal, TypedDict\n","\n","from langchain.chains.combine_documents.reduce import (\n","    acollapse_docs,\n","    split_list_of_docs,\n",")\n","from langchain_core.documents import Document\n","from langgraph.constants import Send\n","from langgraph.graph import END, START, StateGraph\n","\n","token_max = 1000\n","\n","\n","def length_function(documents: List[Document]) -> int:\n","    \"\"\"Get number of tokens for input contents.\"\"\"\n","    return sum(llm.get_num_tokens(doc.page_content) for doc in documents)\n","\n","\n","# This will be the overall state of the main graph.\n","# It will contain the input document contents, corresponding\n","# summaries, and a final summary.\n","class OverallState(TypedDict):\n","    # Notice here we use the operator.add\n","    # This is because we want combine all the summaries we generate\n","    # from individual nodes back into one list - this is essentially\n","    # the \"reduce\" part\n","    contents: List[str]\n","    summaries: Annotated[list, operator.add]\n","    collapsed_summaries: List[Document]\n","    final_summary: str\n","\n","\n","# This will be the state of the node that we will \"map\" all\n","# documents to in order to generate summaries\n","class SummaryState(TypedDict):\n","    content: str\n","\n","\n","# Here we generate a summary, given a document\n","async def generate_summary(state: SummaryState):\n","    response = await map_chain.ainvoke(state[\"content\"])\n","    return {\"summaries\": [response]}\n","\n","\n","# Here we define the logic to map out over the documents\n","# We will use this an edge in the graph\n","def map_summaries(state: OverallState):\n","    # We will return a list of `Send` objects\n","    # Each `Send` object consists of the name of a node in the graph\n","    # as well as the state to send to that node\n","    return [\n","        Send(\"generate_summary\", {\"content\": content}) for content in state[\"contents\"]\n","    ]\n","\n","\n","def collect_summaries(state: OverallState):\n","    return {\n","        \"collapsed_summaries\": [Document(summary) for summary in state[\"summaries\"]]\n","    }\n","\n","\n","# Add node to collapse summaries\n","async def collapse_summaries(state: OverallState):\n","    doc_lists = split_list_of_docs(\n","        state[\"collapsed_summaries\"], length_function, token_max\n","    )\n","    results = []\n","    for doc_list in doc_lists:\n","        results.append(await acollapse_docs(doc_list, reduce_chain.ainvoke))\n","\n","    return {\"collapsed_summaries\": results}\n","\n","\n","# This represents a conditional edge in the graph that determines\n","# if we should collapse the summaries or not\n","def should_collapse(\n","    state: OverallState,\n",") -> Literal[\"collapse_summaries\", \"generate_final_summary\"]:\n","    num_tokens = length_function(state[\"collapsed_summaries\"])\n","    if num_tokens > token_max:\n","        return \"collapse_summaries\"\n","    else:\n","        return \"generate_final_summary\"\n","\n","\n","# Here we will generate the final summary\n","async def generate_final_summary(state: OverallState):\n","    response = await reduce_chain.ainvoke(state[\"collapsed_summaries\"])\n","    return {\"final_summary\": response}\n","\n","\n","# Construct the graph\n","# Nodes:\n","graph = StateGraph(OverallState)\n","graph.add_node(\"generate_summary\", generate_summary)  # same as before\n","graph.add_node(\"collect_summaries\", collect_summaries)\n","graph.add_node(\"collapse_summaries\", collapse_summaries)\n","graph.add_node(\"generate_final_summary\", generate_final_summary)\n","\n","# Edges:\n","graph.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n","graph.add_edge(\"generate_summary\", \"collect_summaries\")\n","graph.add_conditional_edges(\"collect_summaries\", should_collapse)\n","graph.add_conditional_edges(\"collapse_summaries\", should_collapse)\n","graph.add_edge(\"generate_final_summary\", END)\n","\n","app = graph.compile()\n","\n","from IPython.display import Image\n","\n","Image(app.get_graph().draw_mermaid_png())\n","\n","async for step in app.astream(\n","    {\"contents\": [doc.page_content for doc in documents]},\n","    {\"recursion_limit\": 20},\n","):\n","    print(list(step.keys()))\n","\n","print(step)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqovV077pl-m","executionInfo":{"status":"ok","timestamp":1731419684507,"user_tz":-330,"elapsed":15992,"user":{"displayName":"Akhil Kunisetty","userId":"10824639933241965364"}},"outputId":"3efbe3a3-e5d7-4839-c5de-a9c188801eae"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["['generate_summary']\n","['generate_summary']\n","['generate_summary']\n","['collect_summaries']\n","['generate_final_summary']\n","{'generate_final_summary': {'final_summary': 'Fruits come in a variety of colors. Apples are typically red, blueberries are blue, and bananas are yellow when ripe. \\n'}}\n"]}]},{"cell_type":"code","source":["#PDF_SUMMARIZER\n","\n","!pip install -U gradio langchain langchain-community pypdf langchain-google-genai langgraph --quiet\n","\n","from google.colab import userdata\n","import os\n","os.environ['GOOGLE_API_KEY'] = userdata.get('AAPI')\n","\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.chains.summarize import load_summarize_chain\n","\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","llm = ChatGoogleGenerativeAI(\n","      model=\"gemini-1.5-flash\",\n","      temperature=0,\n","      max_tokens=None,\n","      timeout=None,\n","      max_retries=2\n",")\n","\n","def summarize_pdf(pdf_file_path):\n","    loader = PyPDFLoader(pdf_file_path)\n","    docs = loader.load_and_split()\n","    chain = load_summarize_chain(llm, chain_type=\"refine\")\n","    summary = chain.invoke(docs)\n","\n","    return summary\n","\n","summary = summarize_pdf(\"/content/LLM_REF.pdf\")\n","\n","print(summary['output_text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwq3u1UsXH6P","executionInfo":{"status":"ok","timestamp":1731419602709,"user_tz":-330,"elapsed":18069,"user":{"displayName":"Akhil Kunisetty","userId":"10824639933241965364"}},"outputId":"5247712d-671d-4ae4-f465-84ea35132e2f"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Diwali, India's most significant holiday, is a celebration of light over darkness.  While rooted in Hinduism, it has evolved into a national festival celebrated by various religious communities, including Jains, Sikhs, and Buddhists, each with their own interpretations and historical significance. \n","\n"]}]}]}