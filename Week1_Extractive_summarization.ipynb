{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#the frequency method\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "text = '''Automatic summarization is the process of shortening a set of data computationally, to create a subset (a summary) that represents the most important or relevant information within the original content. Artificial intelligence algorithms are commonly developed and employed to achieve this, specialized for different types of data.\n",
        "\n",
        "Text summarization is usually implemented by natural language processing methods, designed to locate the most informative sentences in a given document. On the other hand, visual content can be summarized using computer vision algorithms.'''\n",
        "\n",
        "\n",
        "def solve(text):\n",
        "    stopwords1 = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Create a frequency table for the words\n",
        "    freqTable = {}\n",
        "    for word in words:\n",
        "        word = word.lower()\n",
        "        if word in stopwords1:\n",
        "            continue\n",
        "        if word in freqTable:\n",
        "            freqTable[word] += 1\n",
        "        else:\n",
        "            freqTable[word] = 1\n",
        "\n",
        "    # Score sentences based on word frequency\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentenceValue = {}\n",
        "    for sentence in sentences:\n",
        "        for word, freq in freqTable.items():\n",
        "            if word in sentence.lower():\n",
        "                if sentence in sentenceValue:\n",
        "                    sentenceValue[sentence] += freq\n",
        "                else:\n",
        "                    sentenceValue[sentence] = freq\n",
        "\n",
        "    # Sort sentences by score\n",
        "    sorted_sentences = sorted(sentenceValue.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    # Select top 3 sentences for the summary\n",
        "    summary = ' '.join([sentence for sentence, score in sorted_sentences[:3]])\n",
        "\n",
        "    return summary.strip()\n",
        "\n",
        "summary = solve(text)\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8yCA2AekdXA",
        "outputId": "f06ab4aa-1177-4890-aa61-88c6eafad350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic summarization is the process of shortening a set of data computationally, to create a subset (a summary) that represents the most important or relevant information within the original content. Text summarization is usually implemented by natural language processing methods, designed to locate the most informative sentences in a given document. Artificial intelligence algorithms are commonly developed and employed to achieve this, specialized for different types of data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Latent Semantic Analyzer (LSA)\n",
        "\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "def lsa_method(text):\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer_lsa = LsaSummarizer()\n",
        "    summary = summarizer_lsa(parser.document, 1)\n",
        "    dp = [str(sentence) for sentence in summary]\n",
        "    final_sentence = ' '.join(dp)\n",
        "    return final_sentence\n",
        "\n",
        "text = ''' Text summarization is usually implemented by natural language processing methods.It is designed to locate the most informative sentences in a given document.[1] On the other hand, visual content can be summarized using computer vision algorithms. Image summarization is the subject of ongoing research; existing approaches typically attempt to display the most representative images from a given image collection, or generate a video that only includes the most important content from the entire collection.[2][3][4] Video summarization algorithms identify and extract from the original video content the most important frames (key-frames), and/or the most important video segments (key-shots), normally in a temporally ordered fashion.[5][6][7][8] Video summaries simply retain a carefully selected subset of the original video frames and, therefore, are not identical to the output of video synopsis algorithms, where new video frames are being synthesized based on the original video content'''\n",
        "final = lsa_method(text)\n",
        "print(final)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hySyuhTAhqXT",
        "outputId": "53324b09-b741-477d-ae90-5dc4e0ff62c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] On the other hand, visual content can be summarized using computer vision algorithms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JpOxxEJeWk-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#luhn method\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.luhn import LuhnSummarizer\n",
        "\n",
        "def lunh_method(text):\n",
        "  parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "  summarizer_luhn = LuhnSummarizer()\n",
        "  summary_1 = summarizer_luhn(parser.document,1)\n",
        "  dp = [str(sentence) for sentence in summary_1]\n",
        "  final_sentence = ' '.join(dp)\n",
        "  return final_sentence\n",
        "\n",
        "text = ''' Text summarization is usually implemented by natural language processing methods.It is designed to locate the most informative sentences in a given document.[1] On the other hand, visual content can be summarized using computer vision algorithms. Image summarization is the subject of ongoing research. existing approaches typically attempt to display the most representative images from a given image collection, or generate a video that only includes the most important content from the entire collection.[2][3][4] Video summarization algorithms identify and extract from the original video content the most important frames (key-frames), and/or the most important video segments (key-shots), normally in a temporally ordered fashion.[5][6][7][8] Video summaries simply retain a carefully selected subset of the original video frames and, therefore, are not identical to the output of video synopsis algorithms, where new video frames are being synthesized based on the original video content'''\n",
        "final = lunh_method(text)\n",
        "print(final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xnhghV1UjYr",
        "outputId": "eafd4744-0646-4376-8d5d-b72787574aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2][3][4] Video summarization algorithms identify and extract from the original video content the most important frames (key-frames), and/or the most important video segments (key-shots), normally in a temporally ordered fashion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lex rank method\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "def sumy_method(text):\n",
        "  parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "  summarizer = LexRankSummarizer()\n",
        "  summary = summarizer(parser.document, 4)\n",
        "  dp = []\n",
        "  for i in summary:\n",
        "    lp = str(i)\n",
        "    dp.append(lp)\n",
        "    final_sentence = ' '.join(dp)\n",
        "  return final_sentence\n",
        "text = ''' Text summarization is usually implemented by natural language processing methods.It is designed to locate the most informative sentences in a given document.[1] On the other hand, visual content can be summarized using computer vision algorithms. Image summarization is the subject of ongoing research. existing approaches typically attempt to display the most representative images from a given image collection, or generate a video that only includes the most important content from the entire collection.[2][3][4] Video summarization algorithms identify and extract from the original video content the most important frames (key-frames), and/or the most important video segments (key-shots), normally in a temporally ordered fashion.[5][6][7][8] Video summaries simply retain a carefully selected subset of the original video frames and, therefore, are not identical to the output of video synopsis algorithms, where new video frames are being synthesized based on the original video content'''\n",
        "final = sumy_method(text)\n",
        "print(final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4mNhSicWm6W",
        "outputId": "09d18fa2-e3af-4e38-a781-e0ca71b72087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text summarization is usually implemented by natural language processing methods.It is designed to locate the most informative sentences in a given document. [1] On the other hand, visual content can be summarized using computer vision algorithms. Image summarization is the subject of ongoing research. [2][3][4] Video summarization algorithms identify and extract from the original video content the most important frames (key-frames), and/or the most important video segments (key-shots), normally in a temporally ordered fashion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "!pip install sumy\n"
      ],
      "metadata": {
        "id": "SwzIs3reorBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#                      INPUT METHOD  NAME FUNCTION FOR EXTRACTIVE SUMMARIZATION\n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import sumy\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "from sumy.summarizers.luhn import LuhnSummarizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "\n",
        "def frequency(text,lines):\n",
        "    line=lines\n",
        "    stopwords1 = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Create a frequency table for the words\n",
        "    freqTable = {}\n",
        "    for word in words:\n",
        "        word = word.lower()\n",
        "        if word in stopwords1:\n",
        "            continue\n",
        "        if word in freqTable:\n",
        "            freqTable[word] += 1\n",
        "        else:\n",
        "            freqTable[word] = 1\n",
        "\n",
        "    # Score sentences based on word frequency\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentenceValue = {}\n",
        "    for sentence in sentences:\n",
        "        for word, freq in freqTable.items():\n",
        "            if word in sentence.lower():\n",
        "                if sentence in sentenceValue:\n",
        "                    sentenceValue[sentence] += freq\n",
        "                else:\n",
        "                    sentenceValue[sentence] = freq\n",
        "\n",
        "    # Sort sentences by score\n",
        "    sorted_sentences = sorted(sentenceValue.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    # Select top 3 sentences for the summary\n",
        "    summary = ' '.join([sentence for sentence, score in sorted_sentences[:line]])\n",
        "\n",
        "    return summary.strip()\n",
        "\n",
        "#Latent Semantic Analyzer (LSA)\n",
        "\n",
        "def lsa(text,lines):\n",
        "    line=lines\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer_lsa = LsaSummarizer()\n",
        "    summary = summarizer_lsa(parser.document, line)\n",
        "    dp = [str(sentence) for sentence in summary]\n",
        "    final_sentence = ' '.join(dp)\n",
        "    return final_sentence\n",
        "\n",
        "#luhn method\n",
        "\n",
        "def lunh(text,lines):\n",
        "  line=lines\n",
        "  parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "  summarizer_luhn = LuhnSummarizer()\n",
        "  summary_1 = summarizer_luhn(parser.document,line)\n",
        "  dp = [str(sentence) for sentence in summary_1]\n",
        "  final_sentence = ' '.join(dp)\n",
        "  return final_sentence\n",
        "\n",
        "#lex rank method\n",
        "def lexrank(text,lines):\n",
        "  line=lines\n",
        "  parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "  summarizer = LexRankSummarizer()\n",
        "  summary = summarizer(parser.document, line)\n",
        "  dp = []\n",
        "  for i in summary:\n",
        "    lp = str(i)\n",
        "    dp.append(lp)\n",
        "    final_sentence = ' '.join(dp)\n",
        "  return final_sentence\n",
        "\n",
        "text = ''' Text summarization is usually implemented by natural language processing methods.It is designed to locate the most informative sentences in a given document.[1] On the other hand, visual content can be summarized using computer vision algorithms. Image summarization is the subject of ongoing research. existing approaches typically attempt to display the most representative images from a given image collection, or generate a video that only includes the most important content from the entire collection.[2][3][4] Video summarization algorithms identify and extract from the original video content the most important frames (key-frames), and/or the most important video segments (key-shots), normally in a temporally ordered fashion.[5][6][7][8] Video summaries simply retain a carefully selected subset of the original video frames and, therefore, are not identical to the output of video synopsis algorithms, where new video frames are being synthesized based on the original video content'''\n",
        "\n",
        "methods = {\n",
        "    \"frequency\":frequency,\n",
        "    \"lsa\":lsa,\n",
        "    \"luhn\":lunh,\n",
        "    \"lexrank\":lexrank\n",
        "}\n",
        "method_name = input(\"Enter method : \")\n",
        "lines = int(input(\"Enter number of lines: \"))\n",
        "\n",
        "if method_name in methods:\n",
        "    final = methods[method_name](text, lines)\n",
        "    print(final)\n",
        "else:\n",
        "    print(\"Invalid method name.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXlnO3poj4zr",
        "outputId": "70692d70-3862-4c36-c77c-03e9fad248ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter method : lsa\n",
            "Enter number of lines: 1\n",
            "[1] On the other hand, visual content can be summarized using computer vision algorithms.\n"
          ]
        }
      ]
    }
  ]
}