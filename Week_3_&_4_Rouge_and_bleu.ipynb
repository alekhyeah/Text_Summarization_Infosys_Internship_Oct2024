{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+bkOI+YcFW3SXUTgkDJP3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/springboardmentor0327/Text_Summarization_Infosys_Internship_Oct2024/blob/BandariRohith/Week_3_%26_4_Rouge_and_bleu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqyHJ0GFfgbP",
        "outputId": "dfd5a982-8d0c-4c5b-f004-4e9cb3eda3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets --quiet\n",
        "!pip install rouge_score --quiet\n",
        "!pip install pyarrow --quiet\n",
        "!pip install nltk --quiet\n",
        "!pip install sumy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    T5Tokenizer, T5ForConditionalGeneration,\n",
        "    BartTokenizer, BartForConditionalGeneration\n",
        ")\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test[:1%]\")"
      ],
      "metadata": {
        "id": "rP24BCrugHVU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extractive methods"
      ],
      "metadata": {
        "id": "zWo0X8DYit1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from collections import Counter\n",
        "from heapq import nlargest\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "def generate_summary_frequency(text, num_sentences=3):\n",
        "    \"\"\"Summarize text using Frequency method.\"\"\"\n",
        "    sentences = sent_tokenize(text)\n",
        "    words = word_tokenize(text.lower())\n",
        "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "    words = [word for word in words if word.isalnum() and word not in stopwords]\n",
        "\n",
        "    word_freq = Counter(words)\n",
        "    sentence_scores = {}\n",
        "    for sent in sentences:\n",
        "        for word in word_tokenize(sent.lower()):\n",
        "            if word in word_freq:\n",
        "                sentence_scores[sent] = sentence_scores.get(sent, 0) + word_freq[word]\n",
        "\n",
        "    top_sentences = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
        "    return \" \".join(top_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2BQyzj-ipfF",
        "outputId": "1a18537b-b6c8-41e4-fcac-539d55719947"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n",
        "\n",
        "def generate_summary_textrank(text, num_sentences=3):\n",
        "    \"\"\"Summarize text using TextRank.\"\"\"\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer = TextRankSummarizer()\n",
        "    summary = summarizer(parser.document, num_sentences)\n",
        "    return \" \".join([str(sentence) for sentence in summary])\n"
      ],
      "metadata": {
        "id": "D6LF5Yhii0oU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T5\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "# BART\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "Z_V0pxJAgNtV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Gemini LLM\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('API')\n",
        "!pip install --upgrade --quiet tiktoken langchain langchain-google-genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "def load_llm(model=\"gemini-1.5-pro\"):\n",
        "    if model == \"gemini-1.5-pro\":\n",
        "        return ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-1.5-pro\",\n",
        "            temperature=0,\n",
        "            max_tokens=None,\n",
        "            timeout=None,\n",
        "            max_retries=2)\n",
        "    elif model == \"gemini-1.5-flash\":\n",
        "        return ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-1.5-flash\",\n",
        "            temperature=0,\n",
        "            max_tokens=None,\n",
        "            timeout=None,\n",
        "            max_retries=2)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model name\")\n",
        "\n",
        "def get_prompt_template():\n",
        "    return ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Write a concise summary of the following in {num_words} words:\\n\\n\",\n",
        "            ),\n",
        "            (\"human\", \"{context}\")\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def summarize_text(text, num_words=50, model=\"gemini-1.5-pro\"):\n",
        "    llm = load_llm(model)\n",
        "    prompt = get_prompt_template()\n",
        "    chain = prompt | llm\n",
        "    result = chain.invoke({\"context\": text, \"num_words\": num_words})\n",
        "    return result.content"
      ],
      "metadata": {
        "id": "5X5q0eTUgPSS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary_t5(text):\n",
        "    \"\"\"Generate summary using T5.\"\"\"\n",
        "    preprocessed_text = \"summarize: \" + text\n",
        "    inputs = t5_tokenizer.encode(preprocessed_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    summary_ids = t5_model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    return t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def generate_summary_bart(text):\n",
        "    \"\"\"Generate summary using BART.\"\"\"\n",
        "    inputs = bart_tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = bart_model.generate(inputs[\"input_ids\"], num_beams=4, max_length=150, min_length=40, length_penalty=2.0, early_stopping=True)\n",
        "    return bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "pFpF0g5VgS8I"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rouge(reference, hypothesis):\n",
        "    \"\"\"Calculate ROUGE scores.\"\"\"\n",
        "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "    scores = scorer.score(reference, hypothesis)\n",
        "    return {\n",
        "        \"ROUGE-1\": scores[\"rouge1\"].fmeasure,\n",
        "        \"ROUGE-2\": scores[\"rouge2\"].fmeasure,\n",
        "        \"ROUGE-L\": scores[\"rougeL\"].fmeasure,\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_bleu(reference, hypothesis, weights=(0.25, 0.25, 0.25, 0.25)): #default weights for 1-gram to 4-gram\n",
        "    \"\"\"Calculate BLEU score with customizable N-grams.\"\"\"\n",
        "    reference_tokens = reference.split()\n",
        "    hypothesis_tokens = hypothesis.split()\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    score = sentence_bleu(\n",
        "        [reference_tokens],\n",
        "        hypothesis_tokens,\n",
        "        weights=weights,\n",
        "        smoothing_function=smoothie\n",
        "    )\n",
        "    return score\n",
        "\n",
        "#Weights can be altered based on the number of N-grams we whish to have\n",
        "#Use (1.0, 0.0, 0.0, 0.0) for only unigrams (1-grams).\n",
        "#Use (0.5, 0.5, 0.0, 0.0) for unigrams and bigrams (1-grams and 2-grams).\n",
        "#Use (0.33, 0.33, 0.33, 0.0) for unigrams, bigrams, and trigrams.\n",
        "\n",
        "def evaluate_summarization_models():\n",
        "    for i, sample in enumerate(dataset):\n",
        "        article = sample[\"article\"]\n",
        "        reference_summary = sample[\"highlights\"]\n",
        "\n",
        "        print(\"\\n--- Sample Selected ---\")\n",
        "        print(f\"**Original Article**:\\n{article}\\n\")\n",
        "        print(f\"**Sample Summary**:\\n{reference_summary}\\n\")\n",
        "\n",
        "        # Generate summaries\n",
        "        t5_summary = generate_summary_t5(article)\n",
        "        bart_summary = generate_summary_bart(article)\n",
        "        llm_summary = summarize_text(article, num_words=50, model=\"gemini-1.5-flash\")\n",
        "        freq_summary = generate_summary_frequency(article)\n",
        "        textrank_summary = generate_summary_textrank(article)\n",
        "\n",
        "        print(\"--- Generated Summaries ---\")\n",
        "        print(f\"**T5 Summary**:\\n{t5_summary}\\n\")\n",
        "        print(f\"**BART Summary**:\\n{bart_summary}\\n\")\n",
        "        print(f\"**Google Gemini Summary**:\\n{llm_summary}\\n\")\n",
        "        print(f\"**Frequency-Based Summary**:\\n{freq_summary}\\n\")\n",
        "        print(f\"**TextRank Summary**:\\n{textrank_summary}\\n\")\n",
        "\n",
        "\n",
        "        for model_name, hypothesis in [\n",
        "            (\"T5\", t5_summary),\n",
        "            (\"BART\", bart_summary),\n",
        "            (\"Google Gemini\", llm_summary),\n",
        "            (\"Frequency-Based\", freq_summary),\n",
        "            (\"TextRank\", textrank_summary),\n",
        "        ]:\n",
        "            rouge_scores = calculate_rouge(reference_summary, hypothesis)\n",
        "            bleu_score = calculate_bleu(reference_summary, hypothesis)\n",
        "\n",
        "            print(f\"--- {model_name} Scores ---\")\n",
        "            print(f\"ROUGE-1: {rouge_scores['ROUGE-1']:.4f}\")\n",
        "            print(f\"ROUGE-2: {rouge_scores['ROUGE-2']:.4f}\")\n",
        "            print(f\"ROUGE-L: {rouge_scores['ROUGE-L']:.4f}\")\n",
        "            print(f\"BLEU: {bleu_score:.4f}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        if i >= 1:\n",
        "            break\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    evaluate_summarization_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x20E5eGXgVVS",
        "outputId": "fe59c97d-0a21-4741-f6a6-25c9868e9bef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample Selected ---\n",
            "**Original Article**:\n",
            "(CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, including East Jerusalem, since June 13, 2014.\" Later that month, the ICC opened a preliminary examination into the situation in Palestinian territories, paving the way for possible war crimes investigations against Israelis. As members of the court, Palestinians may be subject to counter-charges as well. Israel and the United States, neither of which is an ICC member, opposed the Palestinians' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki, speaking at Wednesday's ceremony, said it was a move toward greater justice. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. \"Indeed, today brings us closer to our shared goals of justice and peace.\" Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute. These are substantive commitments, which cannot be taken lightly,\" she said. Rights group Human Rights Watch welcomed the development. \"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court's treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"What's objectionable is the attempts to undermine international justice, not Palestine's decision to join a treaty to which over 100 countries around the world are members.\" In January, when the preliminary ICC examination was opened, Israeli Prime Minister Benjamin Netanyahu described it as an outrage, saying the court was overstepping its boundaries. The United States also said it \"strongly\" disagreed with the court's decision. \"As we have said repeatedly, we do not believe that Palestine is a state and therefore we do not believe that it is eligible to join the ICC,\" the State Department said in a statement. It urged the warring sides to resolve their differences through direct negotiations. \"We will continue to oppose actions against Israel at the ICC as counterproductive to the cause of peace,\" it said. But the ICC begs to differ with the definition of a state for its purposes and refers to the territories as \"Palestine.\" While a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to investigate suspects on both sides. Prosecutor Fatou Bensouda said her office would \"conduct its analysis in full independence and impartiality.\" The war between Israel and Hamas militants in Gaza last summer left more than 2,000 people dead. The inquiry will include alleged war crimes committed since June. The International Criminal Court was set up in 2002 to prosecute genocide, crimes against humanity and war crimes. CNN's Vasco Cotovio, Kareem Khadder and Faith Karimi contributed to this report.\n",
            "\n",
            "**Sample Summary**:\n",
            "Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
            "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n",
            "\n",
            "--- Generated Summaries ---\n",
            "**T5 Summary**:\n",
            "the palestinians signed the ICC's founding Rome Statute in January. the ICC also accepted its jurisdiction over alleged crimes committed in the occupied Palestinian territory. the ICC opened a preliminary examination into the situation in the occupied territories.\n",
            "\n",
            "**BART Summary**:\n",
            "The Palestinian Authority becomes the 123rd member of the International Criminal Court. The move gives the court jurisdiction over alleged crimes in Palestinian territories. Israel and the United States opposed the Palestinians' efforts to join the body.\n",
            "\n",
            "**Google Gemini Summary**:\n",
            "Palestine officially joined the International Criminal Court (ICC), granting the court jurisdiction over alleged crimes in Palestinian territories since June 2014.  This move, opposed by Israel and the US, allows for potential war crimes investigations against both sides, furthering the pursuit of justice and peace, though preliminary.\n",
            "\n",
            "\n",
            "**Frequency-Based Summary**:\n",
            "\"Governments seeking to penalize Palestine for joining the ICC should immediately end their pressure, and countries that support universal acceptance of the court's treaty should speak out to welcome its membership,\" said Balkees Jarrah, international justice counsel for the group. \"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories.\n",
            "\n",
            "**TextRank Summary**:\n",
            "\"As Palestine formally becomes a State Party to the Rome Statute today, the world is also a step closer to ending a long era of impunity and injustice,\" he said, according to an ICC news release. Judge Kuniko Ozaki, a vice president of the ICC, said acceding to the treaty was just the first step for the Palestinians. \"As the Rome Statute today enters into force for the State of Palestine, Palestine acquires all the rights as well as responsibilities that come with being a State Party to the Statute.\n",
            "\n",
            "--- T5 Scores ---\n",
            "ROUGE-1: 0.3836\n",
            "ROUGE-2: 0.1972\n",
            "ROUGE-L: 0.3562\n",
            "BLEU: 0.1486\n",
            "--------------------------------------------------\n",
            "--- BART Scores ---\n",
            "ROUGE-1: 0.5352\n",
            "ROUGE-2: 0.3768\n",
            "ROUGE-L: 0.4789\n",
            "BLEU: 0.2535\n",
            "--------------------------------------------------\n",
            "--- Google Gemini Scores ---\n",
            "ROUGE-1: 0.5432\n",
            "ROUGE-2: 0.2785\n",
            "ROUGE-L: 0.4444\n",
            "BLEU: 0.1835\n",
            "--------------------------------------------------\n",
            "--- Frequency-Based Scores ---\n",
            "ROUGE-1: 0.2429\n",
            "ROUGE-2: 0.1014\n",
            "ROUGE-L: 0.1429\n",
            "BLEU: 0.0351\n",
            "--------------------------------------------------\n",
            "--- TextRank Scores ---\n",
            "ROUGE-1: 0.1452\n",
            "ROUGE-2: 0.0164\n",
            "ROUGE-L: 0.1129\n",
            "BLEU: 0.0060\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Sample Selected ---\n",
            "**Original Article**:\n",
            "(CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. That's according to Washington State University, where the dog -- a friendly white-and-black bully breed mix now named Theia -- has been receiving care at the Veterinary Teaching Hospital. Four days after her apparent death, the dog managed to stagger to a nearby farm, dirt-covered and emaciated, where she was found by a worker who took her to a vet for help. She was taken in by Moses Lake, Washington, resident Sara Mellado. \"Considering everything that she's been through, she's incredibly gentle and loving,\" Mellado said, according to WSU News. \"She's a true miracle dog and she deserves a good life.\" Theia is only one year old but the dog's brush with death did not leave her unscathed. She suffered a dislocated jaw, leg injuries and a caved-in sinus cavity -- and still requires surgery to help her breathe. The veterinary hospital's Good Samaritan Fund committee awarded some money to help pay for the dog's treatment, but Mellado has set up a fundraising page to help meet the remaining cost of the dog's care. She's also created a Facebook page to keep supporters updated. Donors have already surpassed the $10,000 target, inspired by Theia's tale of survival against the odds. On the fundraising page, Mellado writes, \"She is in desperate need of extensive medical procedures to fix her nasal damage and reset her jaw. I agreed to foster her until she finally found a loving home.\" She is dedicated to making sure Theia gets the medical attention she needs, Mellado adds, and wants to \"make sure she gets placed in a family where this will never happen to her again!\" Any additional funds raised will be \"paid forward\" to help other animals. Theia is not the only animal to apparently rise from the grave in recent weeks. A cat in Tampa, Florida, found seemingly dead after he was hit by a car in January, showed up alive in a neighbor's yard five days after he was buried by his owner. The cat was in bad shape, with maggots covering open wounds on his body and a ruined left eye, but remarkably survived with the help of treatment from the Humane Society.\n",
            "\n",
            "**Sample Summary**:\n",
            "Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\n",
            "\"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia .\n",
            "\n",
            "--- Generated Summaries ---\n",
            "**T5 Summary**:\n",
            "theia is a friendly white-and-black bully breed mix now named theia. she was found by a worker who took her to a vet for help. the dog's brush with death did not leave her unscathed.\n",
            "\n",
            "**BART Summary**:\n",
            "Theia, a one-year-old bully breed mix, was hit by a car and buried in a field. Four days after her apparent death, the dog managed to stagger to a nearby farm. She suffered a dislocated jaw, leg injuries and a caved-in sinus cavity. She still requires surgery to help her breathe.\n",
            "\n",
            "**Google Gemini Summary**:\n",
            "A Washington State dog, Theia, survived being hit by a car, bludgeoned, and buried.  Found four days later, emaciated and injured, she's receiving treatment for her severe injuries.  A fundraising campaign has exceeded its goal to cover her extensive medical costs, showcasing her remarkable resilience.\n",
            "\n",
            "\n",
            "**Frequency-Based Summary**:\n",
            "The veterinary hospital's Good Samaritan Fund committee awarded some money to help pay for the dog's treatment, but Mellado has set up a fundraising page to help meet the remaining cost of the dog's care. That's according to Washington State University, where the dog -- a friendly white-and-black bully breed mix now named Theia -- has been receiving care at the Veterinary Teaching Hospital. She is dedicated to making sure Theia gets the medical attention she needs, Mellado adds, and wants to \"make sure she gets placed in a family where this will never happen to her again!\"\n",
            "\n",
            "**TextRank Summary**:\n",
            "A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently whacked on the head with a hammer in a misguided mercy killing and then buried in a field -- only to survive. Four days after her apparent death, the dog managed to stagger to a nearby farm, dirt-covered and emaciated, where she was found by a worker who took her to a vet for help. She is dedicated to making sure Theia gets the medical attention she needs, Mellado adds, and wants to \"make sure she gets placed in a family where this will never happen to her again!\"\n",
            "\n",
            "--- T5 Scores ---\n",
            "ROUGE-1: 0.4444\n",
            "ROUGE-2: 0.0759\n",
            "ROUGE-L: 0.2716\n",
            "BLEU: 0.0256\n",
            "--------------------------------------------------\n",
            "--- BART Scores ---\n",
            "ROUGE-1: 0.4742\n",
            "ROUGE-2: 0.2316\n",
            "ROUGE-L: 0.3918\n",
            "BLEU: 0.1282\n",
            "--------------------------------------------------\n",
            "--- Google Gemini Scores ---\n",
            "ROUGE-1: 0.3146\n",
            "ROUGE-2: 0.1149\n",
            "ROUGE-L: 0.2472\n",
            "BLEU: 0.0605\n",
            "--------------------------------------------------\n",
            "--- Frequency-Based Scores ---\n",
            "ROUGE-1: 0.2621\n",
            "ROUGE-2: 0.0420\n",
            "ROUGE-L: 0.1103\n",
            "BLEU: 0.0131\n",
            "--------------------------------------------------\n",
            "--- TextRank Scores ---\n",
            "ROUGE-1: 0.3636\n",
            "ROUGE-2: 0.1053\n",
            "ROUGE-L: 0.2857\n",
            "BLEU: 0.0617\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the excel file with the scores\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "!pip install xlsxwriter --quiet\n",
        "from xlsxwriter import Workbook\n",
        "\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test[:1%]\")\n",
        "\n",
        "samples = dataset.select(range(6))\n",
        "\n",
        "results = []\n",
        "\n",
        "def evaluate_summarization_models():\n",
        "    for i, sample in enumerate(samples):\n",
        "        article = sample[\"article\"]\n",
        "        reference_summary = sample[\"highlights\"]\n",
        "\n",
        "        t5_summary = generate_summary_t5(article)\n",
        "        bart_summary = generate_summary_bart(article)\n",
        "        llm_summary = summarize_text(article, num_words=50, model=\"gemini-1.5-flash\")\n",
        "        freq_summary = generate_summary_frequency(article)\n",
        "        textrank_summary = generate_summary_textrank(article)\n",
        "\n",
        "        for model_name, hypothesis in [\n",
        "            (\"T5\", t5_summary),\n",
        "            (\"BART\", bart_summary),\n",
        "            (\"Google Gemini\", llm_summary),\n",
        "            (\"Frequency-Based\", freq_summary),\n",
        "            (\"TextRank\", textrank_summary),\n",
        "        ]:\n",
        "            rouge_scores = calculate_rouge(reference_summary, hypothesis)\n",
        "            bleu_score = calculate_bleu(reference_summary, hypothesis)\n",
        "\n",
        "            results.append({\n",
        "                \"Model Name\": model_name,\n",
        "                \"Original Article\": article,\n",
        "                \"Sample Summary\": reference_summary,\n",
        "                \"Generated Summary\": hypothesis,\n",
        "                \"ROUGE-1\": rouge_scores[\"ROUGE-1\"],\n",
        "                \"ROUGE-2\": rouge_scores[\"ROUGE-2\"],\n",
        "                \"ROUGE-L\": rouge_scores[\"ROUGE-L\"],\n",
        "                \"BLEU\": bleu_score,\n",
        "            })\n",
        "\n",
        "\n",
        "def save_results_to_excel_by_model(results, file_name=\"summarization_results_of_models.xlsx\"):\n",
        "    # Convert the results list into a DataFrame\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Create a Pandas ExcelWriter object to save multiple sheets\n",
        "    with pd.ExcelWriter(file_name, engine=\"xlsxwriter\") as writer:\n",
        "        # Filter data for each model and save in a separate sheet\n",
        "        for model_name in df[\"Model Name\"].unique():\n",
        "            model_df = df[df[\"Model Name\"] == model_name]\n",
        "            # Write each model's results to a separate sheet\n",
        "            model_df.to_excel(writer, sheet_name=model_name, index=False)\n",
        "\n",
        "    print(f\"Results exported to {file_name} with separate tabs for each model.\")\n",
        "\n",
        "# Use the updated function\n",
        "evaluate_summarization_models()\n",
        "save_results_to_excel_by_model(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw0cs5DAgaFS",
        "outputId": "45f94332-502b-469f-efb0-53e1940bd834"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results exported to summarization_results_of_models.xlsx with separate tabs for each model.\n"
          ]
        }
      ]
    }
  ]
}