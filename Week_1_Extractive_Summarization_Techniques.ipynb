{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbOVDwm+qWFm9DQMsFkCBb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Frequency Method"
      ],
      "metadata": {
        "id": "3Pc_WrJ931WO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qase3EWncDu1",
        "outputId": "7d4799f2-4371-416e-92c4-305eb6d11fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Download required resources if not already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = '''Artificial Intelligence (AI) is rapidly transforming the way we live, work, and interact with technology. From healthcare to finance, AI is revolutionizing industries by providing insights, automating tasks, and enhancing decision-making processes. In healthcare, AI-powered tools are assisting doctors in diagnosing diseases more accurately and developing personalized treatment plans. For example, machine learning algorithms can analyze medical images to detect conditions like cancer or heart disease earlier than traditional methods.\n",
        "\n",
        "In the financial sector, AI is being used to detect fraudulent transactions, assess credit risks, and automate trading strategies. These advancements not only save time but also significantly reduce human error. Similarly, the retail industry is leveraging AI to improve customer experiences through personalized recommendations, inventory management, and chatbots that provide instant support.\n",
        "\n",
        "However, as AI continues to evolve, ethical considerations become increasingly important. Issues such as data privacy, algorithmic bias, and the potential displacement of jobs need to be addressed to ensure that AI is developed and deployed responsibly. Governments and organizations worldwide are working on creating policies and frameworks to regulate the use of AI and ensure that its benefits are distributed equitably.\n",
        "\n",
        "Education is another domain where AI is making a significant impact. Intelligent tutoring systems can adapt to the learning pace of individual students, providing customized learning experiences. Virtual assistants are helping educators manage administrative tasks, allowing them to focus more on teaching. Despite its immense potential, the adoption of AI in education faces challenges like unequal access to technology and the need for teacher training.\n",
        "\n",
        "The future of AI holds even greater promise. Advances in natural language processing, computer vision, and robotics are opening up possibilities for innovations that were once thought to be purely science fiction. Autonomous vehicles, for instance, have the potential to transform transportation, reducing accidents and congestion while improving efficiency. At the same time, breakthroughs in AI-driven climate modeling could help us better understand and combat the effects of climate change.\n",
        "\n",
        " '''\n",
        "\n",
        "def solve(text):\n",
        "    # Define stopwords\n",
        "    stopwords1 = set(stopwords.words(\"english\"))\n",
        "\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Create a frequency table for words (ignoring stopwords)\n",
        "    freqTable = {}\n",
        "    for word in words:\n",
        "        word = word.lower()\n",
        "        if word in stopwords1:\n",
        "            continue\n",
        "        if word in freqTable:\n",
        "            freqTable[word] += 1\n",
        "        else:\n",
        "            freqTable[word] = 1\n",
        "\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentenceValue = {}\n",
        "\n",
        "    # Assign a score to each sentence based on the word frequencies\n",
        "    for sentence in sentences:\n",
        "        for word, freq in freqTable.items():\n",
        "            if word in sentence.lower():\n",
        "                if sentence in sentenceValue:\n",
        "                    sentenceValue[sentence] += freq\n",
        "                else:\n",
        "                    sentenceValue[sentence] = freq\n",
        "\n",
        "    # Calculate the average sentence score\n",
        "    sumValues = sum(sentenceValue.values())\n",
        "    average = int(sumValues / len(sentenceValue)) if len(sentenceValue) > 0 else 0\n",
        "\n",
        "    # Generate the summary\n",
        "    summary = ''\n",
        "    for sentence in sentences:\n",
        "        if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
        "            summary += \" \" + sentence\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example usage\n",
        "summary = solve(data)\n",
        "print(\"Summary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0QG_lr9cxcJ",
        "outputId": "ce2fb7b1-44f8-4e73-b857-e446ab3bbc43"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " Similarly, the retail industry is leveraging AI to improve customer experiences through personalized recommendations, inventory management, and chatbots that provide instant support. Issues such as data privacy, algorithmic bias, and the potential displacement of jobs need to be addressed to ensure that AI is developed and deployed responsibly. Despite its immense potential, the adoption of AI in education faces challenges like unequal access to technology and the need for teacher training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.TextRank:**\n",
        "\n",
        "TextRank is a graph-based ranking algorithm (similar to PageRank) used for extractive text summarization. It builds a graph where sentences are nodes, and edges represent similarity between them. The most relevant sentences (those with higher ranks) are extracted for the summary"
      ],
      "metadata": {
        "id": "RN2xAks4jw-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy\n",
        "# Load required packages\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.text_rank import TextRankSummarizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeGu4VhUkuqP",
        "outputId": "1b782b2f-8445-4484-e5ce-df6a5b4c7cd8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sumy\n",
            "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting breadability>=0.1.20 (from sumy)\n",
            "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.32.3)\n",
            "Collecting pycountry>=18.2.23 (from sumy)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.9.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2024.8.30)\n",
            "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: breadability, docopt\n",
            "  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21692 sha256=1c789e2c24f377947f2c2548e9c69d2583e9c357e022224a4c1e98b61af2d025\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=9cf701021f3c741cd79ac124bc7bb096d91984418a6f77a29ed7477fd885cdf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built breadability docopt\n",
            "Installing collected packages: docopt, pycountry, breadability, sumy\n",
            "Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 sumy-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text (you can replace 'text' with any string you want to summarize)\n",
        "text = '''Artificial Intelligence (AI) is rapidly transforming the way we live, work, and interact with technology. From healthcare to finance, AI is revolutionizing industries by providing insights, automating tasks, and enhancing decision-making processes. In healthcare, AI-powered tools are assisting doctors in diagnosing diseases more accurately and developing personalized treatment plans. For example, machine learning algorithms can analyze medical images to detect conditions like cancer or heart disease earlier than traditional methods.\n",
        "\n",
        "In the financial sector, AI is being used to detect fraudulent transactions, assess credit risks, and automate trading strategies. These advancements not only save time but also significantly reduce human error. Similarly, the retail industry is leveraging AI to improve customer experiences through personalized recommendations, inventory management, and chatbots that provide instant support.\n",
        "\n",
        "However, as AI continues to evolve, ethical considerations become increasingly important. Issues such as data privacy, algorithmic bias, and the potential displacement of jobs need to be addressed to ensure that AI is developed and deployed responsibly. Governments and organizations worldwide are working on creating policies and frameworks to regulate the use of AI and ensure that its benefits are distributed equitably.\n",
        "\n",
        "Education is another domain where AI is making a significant impact. Intelligent tutoring systems can adapt to the learning pace of individual students, providing customized learning experiences. Virtual assistants are helping educators manage administrative tasks, allowing them to focus more on teaching. Despite its immense potential, the adoption of AI in education faces challenges like unequal access to technology and the need for teacher training.\n",
        "\n",
        "The future of AI holds even greater promise. Advances in natural language processing, computer vision, and robotics are opening up possibilities for innovations that were once thought to be purely science fiction. Autonomous vehicles, for instance, have the potential to transform transportation, reducing accidents and congestion while improving efficiency. At the same time, breakthroughs in AI-driven climate modeling could help us better understand and combat the effects of climate change.\n",
        "\n",
        " '''\n",
        "\n",
        "# Create a parser with text input and the Tokenizer for English\n",
        "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "# Create a TextRank Summarizer\n",
        "summarizer = TextRankSummarizer()\n",
        "\n",
        "# Generate a summary of 2 sentences\n",
        "summary = summarizer(parser.document, 2)\n",
        "\n",
        "# Collect and print the summarized text\n",
        "text_summary = \"\"\n",
        "for sentence in summary:\n",
        "    text_summary += str(sentence)\n",
        "print(\"Summary:\")\n",
        "print(text_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnqIxqL8lsvl",
        "outputId": "fa4f9bfb-3fe0-4496-88c8-904c414fe379"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "Issues such as data privacy, algorithmic bias, and the potential displacement of jobs need to be addressed to ensure that AI is developed and deployed responsibly.Governments and organizations worldwide are working on creating policies and frameworks to regulate the use of AI and ensure that its benefits are distributed equitably.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.LexRank:**\n",
        "\n",
        "LexRank is a graph-based summarization algorithm where sentences are treated as nodes, and edges represent similarity between sentences (using cosine similarity). Sentences that are most central (have the highest rank) in the graph are selected for the summary."
      ],
      "metadata": {
        "id": "jMM6WDdPmJ8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fORN0ZMRnHrV",
        "outputId": "c7611711-fb5d-4b5f-cb64-5591f526bc2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sumy in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.32.3)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.10/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def sumy_method(text):\n",
        "    # Create a parser with text input and the Tokenizer for English\n",
        "    from sumy.summarizers.lex_rank import LexRankSummarizer # Import LexRankSummarizer here\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "    # Create a LexRank summarizer\n",
        "    summarizer = LexRankSummarizer()\n",
        "\n",
        "    # Generate a summary of 2 sentences\n",
        "    summary = summarizer(parser.document, 2)\n",
        "\n",
        "    # Collect the summary sentences into a list\n",
        "    dp = []\n",
        "    for i in summary:\n",
        "        lp = str(i)\n",
        "        dp.append(lp)\n",
        "\n",
        "    # Join the summary sentences into a final summary string\n",
        "    final_sentence = ' '.join(dp)\n",
        "\n",
        "    return final_sentence\n",
        "\n",
        "# Example usage\"\n",
        "text ='''Artificial Intelligence (AI) is rapidly transforming the way we live, work, and interact with technology. From healthcare to finance, AI is revolutionizing industries by providing insights, automating tasks, and enhancing decision-making processes. In healthcare, AI-powered tools are assisting doctors in diagnosing diseases more accurately and developing personalized treatment plans. For example, machine learning algorithms can analyze medical images to detect conditions like cancer or heart disease earlier than traditional methods.\n",
        "\n",
        "In the financial sector, AI is being used to detect fraudulent transactions, assess credit risks, and automate trading strategies. These advancements not only save time but also significantly reduce human error. Similarly, the retail industry is leveraging AI to improve customer experiences through personalized recommendations, inventory management, and chatbots that provide instant support.\n",
        "\n",
        "However, as AI continues to evolve, ethical considerations become increasingly important. Issues such as data privacy, algorithmic bias, and the potential displacement of jobs need to be addressed to ensure that AI is developed and deployed responsibly. Governments and organizations worldwide are working on creating policies and frameworks to regulate the use of AI and ensure that its benefits are distributed equitably.\n",
        "\n",
        "Education is another domain where AI is making a significant impact. Intelligent tutoring systems can adapt to the learning pace of individual students, providing customized learning experiences. Virtual assistants are helping educators manage administrative tasks, allowing them to focus more on teaching. Despite its immense potential, the adoption of AI in education faces challenges like unequal access to technology and the need for teacher training.\n",
        "\n",
        "The future of AI holds even greater promise. Advances in natural language processing, computer vision, and robotics are opening up possibilities for innovations that were once thought to be purely science fiction. Autonomous vehicles, for instance, have the potential to transform transportation, reducing accidents and congestion while improving efficiency. At the same time, breakthroughs in AI-driven climate modeling could help us better understand and combat the effects of climate change.\n",
        "\n",
        " '''\n",
        "summary = sumy_method(text)\n",
        "print(\"Summary:\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaZu-ePsnm3o",
        "outputId": "957e5116-e28d-4bd6-cd81-134dd9e1ddd2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "Artificial Intelligence (AI) is rapidly transforming the way we live, work, and interact with technology. From healthcare to finance, AI is revolutionizing industries by providing insights, automating tasks, and enhancing decision-making processes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.LSA (Latent Semantic Analysis):**\n",
        "\n",
        "*   LSA is a matrix decomposition method, where the text data is transformed into a lower-dimensional space. It uses singular value\n",
        "decomposition (SVD) to analyze relationships between terms and concepts in the text.\n",
        "*   In text summarization, LSA captures the underlying meaning of the text and helps in selecting important sentences that represent the overall content.\n",
        "\n",
        "**How LSA Works**:\n",
        "\n",
        "LSA represents text data in a high-dimensional space using term-document matrices and then reduces this space using SVD. This allows it to capture semantic meanings in the text and choose sentences that are representative of the main themes.\n",
        "\n"
      ],
      "metadata": {
        "id": "lP3Q5D8GpZXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sumy\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cad2hoyHphsh",
        "outputId": "92965632-ead0-4c82-818e-441a0f3793ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sumy in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.32.3)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.10/dist-packages (from sumy) (24.6.1)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lsa_method(text):\n",
        "    # Create a parser with text input and the Tokenizer for English\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "\n",
        "    # Import LsaSummarizer here to make it accessible within the function's scope\n",
        "    from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "    # Create an LSA Summarizer\n",
        "    summarizer_lsa = LsaSummarizer()\n",
        "\n",
        "    # Generate a summary of 2 sentences\n",
        "    summary_2 = summarizer_lsa(parser.document, 2)\n",
        "\n",
        "    # Collect the summary sentences into a list\n",
        "    dp = []\n",
        "    for i in summary_2:\n",
        "        lp = str(i)\n",
        "        dp.append(lp)\n",
        "\n",
        "    # Join the summary sentences into a final summary string\n",
        "    final_sentence = ' '.join(dp)\n",
        "\n",
        "    return final_sentence\n",
        "\n",
        "# Example usage\n",
        "text ='''Artificial Intelligence (AI) is rapidly transforming the way we live, work, and interact with technology. From healthcare to finance, AI is revolutionizing industries by providing insights, automating tasks, and enhancing decision-making processes. In healthcare, AI-powered tools are assisting doctors in diagnosing diseases more accurately and developing personalized treatment plans. For example, machine learning algorithms can analyze medical images to detect conditions like cancer or heart disease earlier than traditional methods.\n",
        "\n",
        "In the financial sector, AI is being used to detect fraudulent transactions, assess credit risks, and automate trading strategies. These advancements not only save time but also significantly reduce human error. Similarly, the retail industry is leveraging AI to improve customer experiences through personalized recommendations, inventory management, and chatbots that provide instant support.\n",
        "\n",
        "However, as AI continues to evolve, ethical considerations become increasingly important. Issues such as data privacy, algorithmic bias, and the potential displacement of jobs need to be addressed to ensure that AI is developed and deployed responsibly. Governments and organizations worldwide are working on creating policies and frameworks to regulate the use of AI and ensure that its benefits are distributed equitably.\n",
        "\n",
        "Education is another domain where AI is making a significant impact. Intelligent tutoring systems can adapt to the learning pace of individual students, providing customized learning experiences. Virtual assistants are helping educators manage administrative tasks, allowing them to focus more on teaching. Despite its immense potential, the adoption of AI in education faces challenges like unequal access to technology and the need for teacher training.\n",
        "\n",
        "The future of AI holds even greater promise. Advances in natural language processing, computer vision, and robotics are opening up possibilities for innovations that were once thought to be purely science fiction. Autonomous vehicles, for instance, have the potential to transform transportation, reducing accidents and congestion while improving efficiency. At the same time, breakthroughs in AI-driven climate modeling could help us better understand and combat the effects of climate change.\n",
        "\n",
        " '''\n",
        "summary = lsa_method(text)\n",
        "print(\"Summary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13wGkpfqqpin",
        "outputId": "b85f719c-9e00-4f27-d36a-742dbc7d2860"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "Similarly, the retail industry is leveraging AI to improve customer experiences through personalized recommendations, inventory management, and chatbots that provide instant support. Advances in natural language processing, computer vision, and robotics are opening up possibilities for innovations that were once thought to be purely science fiction.\n"
          ]
        }
      ]
    }
  ]
}